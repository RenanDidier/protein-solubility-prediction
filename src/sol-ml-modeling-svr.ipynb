{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Scikit Learn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Scipy libraries\n",
    "from scipy import stats\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Utils functions\n",
    "from utils.utils import kfold, five_two, read_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = read_datasets(\n",
    "    'x_train.csv',\n",
    "    'x_test.csv',\n",
    "    'y_train.csv',\n",
    "    'y_test.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cross validation scheme to be used for train and test\n",
    "folds = kfold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SVR model with cross validation and default parameters\n",
    "svr = SVR(kernel='rbf', C=1.0, gamma='auto', epsilon=0.1, degree=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1600 candidates, totalling 16000 fits\n",
      "{'C': 10, 'degree': 2, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "# Specify range of hyperparameters to tune\n",
    "hyper_params = {\n",
    "    'kernel': ('linear', 'rbf','poly', 'sigmoid'),\n",
    "    'C':[1, 1.5, 5, 10, 100],\n",
    "    'gamma': [1e-7, 1e-4, 'auto', 'scale'],\n",
    "    'epsilon':[0.1,0.2,0.3,0.4,0.5],\n",
    "    'degree': [1,2,3,4]\n",
    "    }\n",
    "\n",
    "\n",
    "# Call GridSearchCV()\n",
    "model_cv = GridSearchCV(\n",
    "    estimator = SVR(),\n",
    "    param_grid = hyper_params,\n",
    "    scoring= 'r2',\n",
    "    cv = folds,\n",
    "    verbose = 1,\n",
    "    return_train_score=True,\n",
    "    n_jobs = -1,\n",
    "    refit = True\n",
    "    )\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "best_model = model_cv.fit(x_train, np.ravel(y_train)) \n",
    "\n",
    "print(model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new model with best_params_ from grid search\n",
    "\n",
    "svr_best = best_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Results: [0.2449845184409153, 0.24671253738174037, 0.22688614479296676, 0.2396351851711167, 0.25832170284743305, 0.2981504783462676, 0.25189229386532197, 0.25460737558499014, 0.2480827991202349, 0.23813494819473513]\n",
      "Test Results: [0.2625022850749761, 0.10467198420613932, 0.39127596504957196, 0.2715635146099973, 0.22672019392391485, -0.31933591059322075, 0.20390555701599544, 0.04469261682705328, 0.1256176235187545, 0.29059931309576503]\n"
     ]
    }
   ],
   "source": [
    "# Get the results for each split\n",
    "\n",
    "def get_best_model_cv_split_results(best_model, n_splits=10, set_type='train'):\n",
    "    results = []\n",
    "    best_index = best_model.best_index_\n",
    "    for i in range(0, n_splits):\n",
    "        current_split = 'split{}_{}_score'.format(i, set_type)\n",
    "        split_result = best_model.cv_results_[current_split][best_index]\n",
    "        results.append(split_result)\n",
    "\n",
    "    return results\n",
    "\n",
    "print(\"Train Results: {}\".format(get_best_model_cv_split_results(best_model, 10, 'train')))\n",
    "print(\"Test Results: {}\".format(get_best_model_cv_split_results(best_model, 10, 'test')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mean: 0.25074079837457225\n",
      "Test mean: 0.1602213142728947\n"
     ]
    }
   ],
   "source": [
    "#Get the mean for the train and test\n",
    "\n",
    "train_mean = sum(get_best_model_cv_split_results(best_model, 10, 'train'))/10\n",
    "test_mean = sum(get_best_model_cv_split_results(best_model, 10, 'test'))/10\n",
    "\n",
    "print(\"Train mean: {}\".format(train_mean))\n",
    "print(\"Test mean: {}\".format(test_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 score on test set: 0.1072\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(y_test, svr_best.predict(x_test))\n",
    "print(\"The r2 score on test set: {:.4f}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical hypothesis testing\n",
    "\n",
    "Validate if the grid model is better than the base model\n",
    "\n",
    "Null hyphotesis and Alternative hyphotesis\n",
    "* Ho = Best params R2 and Adj R2 <= base model R2 and Adj R2\n",
    "* Ha = Best params R2 and Adj R2 > base model R2 and Adj R2\n",
    "\n",
    "Errors:\n",
    "* Type I Error: false positive, reject the Ho but it is true\n",
    "* Type II Error: false negative, do not reject the Ho but its false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1 score difference = -0.127370\n",
      "Fold  2 score difference = -0.238147\n",
      "Fold  1 score difference = -0.055002\n",
      "Fold  2 score difference = -0.232865\n",
      "Fold  1 score difference = -0.361331\n",
      "Fold  2 score difference = -0.116298\n",
      "Fold  1 score difference = -0.170121\n",
      "Fold  2 score difference = -0.166749\n",
      "Fold  1 score difference = -0.245651\n",
      "Fold  2 score difference = -0.150806\n",
      "Regression 1 mean score and stdev : -0.030837 + 0.067260\n",
      "Regression 2 mean score and stdev : 0.155597 + 0.047330\n",
      "Score difference mean + stdev : -0.186434 + 0.081566\n",
      "t_value for the current test is -1.198431\n"
     ]
    }
   ],
   "source": [
    "five_two(\n",
    "    reg1=svr,\n",
    "    reg2=svr_best,\n",
    "    X=x_train,\n",
    "    y=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1 score difference = -0.169826\n",
      "Fold  2 score difference = -0.317529\n",
      "Fold  1 score difference = -0.073336\n",
      "Fold  2 score difference = -0.310487\n",
      "Fold  1 score difference = -0.481775\n",
      "Fold  2 score difference = -0.155063\n",
      "Fold  1 score difference = -0.226827\n",
      "Fold  2 score difference = -0.222332\n",
      "Fold  1 score difference = -0.327535\n",
      "Fold  2 score difference = -0.201075\n",
      "Regression 1 mean score and stdev : -0.374449 + 0.089680\n",
      "Regression 2 mean score and stdev : -0.125871 + 0.063107\n",
      "Score difference mean + stdev : -0.248579 + 0.108755\n",
      "t_value for the current test is -1.198431\n"
     ]
    }
   ],
   "source": [
    "five_two(\n",
    "    reg1=svr,\n",
    "    reg2=svr_best,\n",
    "    X=x_train,\n",
    "    y=y_train,\n",
    "    metric='adj_r2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t statistic: -2.662\n",
      "p value: 0.045\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "\n",
    "t, p = paired_ttest_5x2cv(estimator1=svr,\n",
    "                          estimator2=svr_best,\n",
    "                          X=x_train, y=y_train,\n",
    "                          scoring='r2',\n",
    "                          random_seed=42)\n",
    "\n",
    "print('t statistic: %.3f' % t)\n",
    "print('p value: %.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/svr_model.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../models/svr_model.joblib'\n",
    "joblib.dump(svr_best, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "What was done:\n",
    "* Create a SVR model with default parameters and another with grid seach + cross validation;\n",
    "* Compare the test scores (r2 and adj r2) from before the grid search and after using T test using 5 x 2-fold cross validation (5 cv of 2 folds);\n",
    "* On grid search: C=1000 did not show better results so it was removed\n",
    "* It seems that the grid model is better than the basemodel with a 80% confidence level"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
