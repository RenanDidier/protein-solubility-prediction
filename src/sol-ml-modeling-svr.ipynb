{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Scikit Learn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Scipy libraries\n",
    "from scipy import stats\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Utils functions\n",
    "from utils.utils import kfold, five_two, read_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = read_datasets(\n",
    "    'x_train.csv',\n",
    "    'x_test.csv',\n",
    "    'y_train.csv',\n",
    "    'y_test.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cross validation scheme to be used for train and test\n",
    "folds = kfold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1600 candidates, totalling 16000 fits\n",
      "{'C': 10, 'degree': 2, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "# Specify range of hyperparameters to tune\n",
    "hyper_params = {\n",
    "    'kernel': ('linear', 'rbf','poly', 'sigmoid'),\n",
    "    'C':[1, 1.5, 5, 10, 100],\n",
    "    'gamma': [1e-7, 1e-4, 'auto', 'scale'],\n",
    "    'epsilon':[0.1,0.2,0.3,0.4,0.5],\n",
    "    'degree': [1,2,3,4]\n",
    "    }\n",
    "\n",
    "\n",
    "# Call GridSearchCV()\n",
    "model_cv = GridSearchCV(\n",
    "    estimator = SVR(),\n",
    "    param_grid = hyper_params,\n",
    "    scoring= 'r2',\n",
    "    cv = folds,\n",
    "    verbose = 1,\n",
    "    return_train_score=True,\n",
    "    n_jobs = -1,\n",
    "    refit = True\n",
    "    )\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "best_model = model_cv.fit(x_train, np.ravel(y_train)) \n",
    "\n",
    "print(model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new model with best_params_ from grid search\n",
    "\n",
    "svr_best = best_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Results: [0.2449845184409153, 0.24671253738174037, 0.22688614479296676, 0.2396351851711167, 0.25832170284743305, 0.2981504783462676, 0.25189229386532197, 0.25460737558499014, 0.2480827991202349, 0.23813494819473513]\n",
      "Validation Results: [0.2625022850749761, 0.10467198420613932, 0.39127596504957196, 0.2715635146099973, 0.22672019392391485, -0.31933591059322075, 0.20390555701599544, 0.04469261682705328, 0.1256176235187545, 0.29059931309576503]\n"
     ]
    }
   ],
   "source": [
    "# Get the results for each split\n",
    "\n",
    "def get_best_model_cv_split_results(best_model, n_splits=10, set_type='train'):\n",
    "    results = []\n",
    "    best_index = best_model.best_index_\n",
    "    for i in range(0, n_splits):\n",
    "        current_split = 'split{}_{}_score'.format(i, set_type)\n",
    "        split_result = best_model.cv_results_[current_split][best_index]\n",
    "        results.append(split_result)\n",
    "\n",
    "    return results\n",
    "\n",
    "print(\"Train Results: {}\".format(get_best_model_cv_split_results(best_model, 10, 'train')))\n",
    "print(\"Validation Results: {}\".format(get_best_model_cv_split_results(best_model, 10, 'test')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mean: 0.25074079837457225\n",
      "Validation mean: 0.1602213142728947\n"
     ]
    }
   ],
   "source": [
    "#Get the mean for the train and test\n",
    "#Pegar o desvio padr√£o\n",
    "\n",
    "train_mean = sum(get_best_model_cv_split_results(best_model, 10, 'train'))/10\n",
    "test_mean = sum(get_best_model_cv_split_results(best_model, 10, 'test'))/10\n",
    "\n",
    "print(\"Train mean: {}\".format(train_mean))\n",
    "print(\"Validation mean: {}\".format(test_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 score on test set: 0.1072\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(y_test, svr_best.predict(x_test))\n",
    "print(\"The r2 score on test set: {:.4f}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/svr_model.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../models/svr_model.joblib'\n",
    "joblib.dump(svr_best, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "What was done:\n",
    "* Create a SVR model with default parameters and another with grid seach + cross validation;\n",
    "* Compare the test scores (r2 and adj r2) from before the grid search and after using T test using 5 x 2-fold cross validation (5 cv of 2 folds);\n",
    "* On grid search: C=1000 did not show better results so it was removed\n",
    "* It seems that the grid model is better than the basemodel with a 80% confidence level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
