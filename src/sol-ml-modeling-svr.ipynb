{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Scikit Learn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Scipy libraries\n",
    "from scipy import stats\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Utils functions\n",
    "from utils.utils import kfold, five_two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../data/\"\n",
    "\n",
    "data_path = folder_path + \"complex_processed_data.csv\"\n",
    "standardized_data_path = folder_path + 'complex_processed_standardized_data.csv'\n",
    "standardized_poutliers_removed_data_path = folder_path + 'complex_processed_standardized_outliers_removed_data.csv'\n",
    "\n",
    "df_solubility = pd.read_csv(standardized_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Dataset\n",
    "\n",
    "Process Dataset before the model creation.\n",
    "The following actions were done:\n",
    "* Split the independent variable from the dependent ones;\n",
    "* Split Dataset for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into X and Y for machine learning\n",
    "\n",
    "df_sol_X = df_solubility.copy()\n",
    "df_sol_X.drop(columns=['solubility'], axis=1, inplace=True)\n",
    "\n",
    "df_sol_y = df_solubility[['solubility']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                        df_sol_X, df_sol_y, \n",
    "                        train_size = 0.8,\n",
    "                        test_size = 0.2,\n",
    "                        random_state = 10\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cross validation scheme to be used for train and test\n",
    "folds = kfold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SVR model with cross validation and default parameters\n",
    "svr = SVR(kernel='rbf', C=1.0, gamma='auto', epsilon=0.1, degree=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1600 candidates, totalling 16000 fits\n",
      "{'C': 1.5, 'degree': 1, 'epsilon': 0.2, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Specify range of hyperparameters to tune\n",
    "hyper_params = {\n",
    "    'kernel': ('linear', 'rbf','poly', 'sigmoid'),\n",
    "    'C':[1, 1.5, 5, 10, 100],\n",
    "    'gamma': [1e-7, 1e-4, 'auto', 'scale'],\n",
    "    'epsilon':[0.1,0.2,0.3,0.4,0.5],\n",
    "    'degree': [1,2,3,4]\n",
    "    }\n",
    "\n",
    "\n",
    "# Call GridSearchCV()\n",
    "model_cv = GridSearchCV(\n",
    "    estimator = SVR(),\n",
    "    param_grid = hyper_params,\n",
    "    scoring= 'r2',\n",
    "    cv = folds,\n",
    "    verbose = 1,\n",
    "    return_train_score=True,\n",
    "    n_jobs = -1,\n",
    "    refit = True\n",
    "    )\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "best_model = model_cv.fit(x_train, np.ravel(y_train)) \n",
    "\n",
    "print(model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new model with best_params_ from grid search\n",
    "# Use cross validation on the best_params_ model\n",
    "\n",
    "svr_best = SVR(\n",
    "    kernel=model_cv.best_params_['kernel'],\n",
    "    C=model_cv.best_params_['C'],\n",
    "    gamma=model_cv.best_params_['gamma'],\n",
    "    epsilon=model_cv.best_params_['epsilon'],\n",
    "    degree=model_cv.best_params_['degree']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical hypothesis testing\n",
    "\n",
    "Validate if the grid model is better than the base model\n",
    "\n",
    "Null hyphotesis and Alternative hyphotesis\n",
    "* Ho = Best params R2 and Adj R2 <= base model R2 and Adj R2\n",
    "* Ha = Best params R2 and Adj R2 > base model R2 and Adj R2\n",
    "\n",
    "Errors:\n",
    "* Type I Error: false positive, reject the Ho but it is true\n",
    "* Type II Error: false negative, do not reject the Ho but its false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1 score difference = -0.027373\n",
      "Fold  2 score difference = -0.034255\n",
      "Fold  1 score difference = 0.034320\n",
      "Fold  2 score difference = 0.029165\n",
      "Fold  1 score difference = -0.070850\n",
      "Fold  2 score difference = -0.081545\n",
      "Fold  1 score difference = -0.008678\n",
      "Fold  2 score difference = -0.058249\n",
      "Fold  1 score difference = 0.000059\n",
      "Fold  2 score difference = 0.017027\n",
      "Regression 1 mean score and stdev : 0.179571 + 0.030092\n",
      "Regression 2 mean score and stdev : 0.199609 + 0.039461\n",
      "Score difference mean + stdev : -0.020038 + 0.039196\n",
      "t_value for the current test is -1.598158\n"
     ]
    }
   ],
   "source": [
    "five_two(\n",
    "    reg1=svr,\n",
    "    reg2=svr_best,\n",
    "    X=df_sol_X,\n",
    "    y=df_sol_y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1 score difference = -0.034649\n",
      "Fold  2 score difference = -0.043304\n",
      "Fold  1 score difference = 0.043443\n",
      "Fold  2 score difference = 0.036869\n",
      "Fold  1 score difference = -0.089684\n",
      "Fold  2 score difference = -0.103085\n",
      "Fold  1 score difference = -0.010984\n",
      "Fold  2 score difference = -0.073636\n",
      "Fold  1 score difference = 0.000075\n",
      "Fold  2 score difference = 0.021524\n",
      "Regression 1 mean score and stdev : -0.037847 + 0.038478\n",
      "Regression 2 mean score and stdev : -0.012504 + 0.050316\n",
      "Score difference mean + stdev : -0.025343 + 0.049574\n",
      "t_value for the current test is -1.601135\n"
     ]
    }
   ],
   "source": [
    "five_two(\n",
    "    reg1=svr,\n",
    "    reg2=svr_best,\n",
    "    X=df_sol_X,\n",
    "    y=df_sol_y,\n",
    "    metric='adj_r2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t statistic: -0.634\n",
      "p value: 0.554\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "\n",
    "t, p = paired_ttest_5x2cv(estimator1=svr,\n",
    "                          estimator2=svr_best,\n",
    "                          X=df_sol_X, y=df_sol_y,\n",
    "                          scoring='r2',\n",
    "                          random_seed=42)\n",
    "\n",
    "print('t statistic: %.3f' % t)\n",
    "print('p value: %.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/svr_model.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../models/svr_model.joblib'\n",
    "joblib.dump(svr_best, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "What was done:\n",
    "* Split dataset in test 20% and train 80%;\n",
    "* Create a SVR model with default parameters and another with grid seach + cross validation;\n",
    "* Compare the test scores (r2 and adj r2) from before the grid search and after using T test using 5 x 2-fold cross validation (5 cv of 2 folds);\n",
    "* On grid search: C=1000 did not show better results so it was removed\n",
    "* It seems that the grid model is better than the basemodel with a 80% confidence level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
