{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor as TN\n",
    "from pytorch_tabnet.augmentations import RegressionSMOTE\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "\n",
    "# Utils functions\n",
    "from utils.utils import read_datasets, kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = read_datasets(\n",
    "    'x_train.csv',\n",
    "    'x_test.csv',\n",
    "    'y_train.csv',\n",
    "    'y_test.csv'\n",
    ")\n",
    "\n",
    "\n",
    "# convert data to tensor\n",
    "x_train_tf = torch.tensor(x_train.values.astype(np.float64)) \n",
    "y_train_tf = torch.tensor(y_train.values)\n",
    "\n",
    "x_test_tf = torch.tensor(x_test.values.astype(np.float64)) \n",
    "y_test_tf = torch.tensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = kfold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabNetRegressor(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def __init__(self, params={}):\n",
    "        super(BaseEstimator, self).__init__()\n",
    "        super(RegressorMixin, self).__init__()\n",
    "        self.tabnet = TN()\n",
    "        self.params = params\n",
    "\n",
    "    def fit(self, X, y=None, params={}):\n",
    "        # print(1)   \n",
    "        if self.params != {}:\n",
    "            self.params = params     \n",
    "        self.tabnet.fit(X, y, **self.params)\n",
    "        return self\n",
    "        # return self.tabnet.fit(check_array(X), np.array(y).reshape(-1, 1))\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        preds = self.tabnet.predict(X)\n",
    "        return preds\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return self.params\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for value, key in params.items():\n",
    "            self.key = value\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.0     |  0:00:00s\n",
      "epoch 1  | loss: 0.0     |  0:00:00s\n",
      "epoch 2  | loss: 0.0     |  0:00:00s\n",
      "epoch 3  | loss: 0.0     |  0:00:00s\n",
      "epoch 4  | loss: 0.0     |  0:00:00s\n",
      "epoch 5  | loss: 0.0     |  0:00:00s\n",
      "epoch 6  | loss: 0.0     |  0:00:00s\n",
      "epoch 7  | loss: 0.0     |  0:00:00s\n",
      "epoch 8  | loss: 0.0     |  0:00:00s\n",
      "epoch 9  | loss: 0.0     |  0:00:00s\n",
      "epoch 10 | loss: 0.0     |  0:00:00s\n",
      "epoch 11 | loss: 0.0     |  0:00:00s\n",
      "epoch 12 | loss: 0.0     |  0:00:00s\n",
      "epoch 13 | loss: 0.0     |  0:00:00s\n",
      "epoch 14 | loss: 0.0     |  0:00:00s\n",
      "epoch 15 | loss: 0.0     |  0:00:00s\n",
      "epoch 16 | loss: 0.0     |  0:00:00s\n",
      "epoch 17 | loss: 0.0     |  0:00:00s\n",
      "epoch 18 | loss: 0.0     |  0:00:00s\n",
      "epoch 19 | loss: 0.0     |  0:00:00s\n",
      "epoch 20 | loss: 0.0     |  0:00:00s\n",
      "epoch 21 | loss: 0.0     |  0:00:00s\n",
      "epoch 22 | loss: 0.0     |  0:00:00s\n",
      "epoch 23 | loss: 0.0     |  0:00:00s\n",
      "epoch 24 | loss: 0.0     |  0:00:00s\n",
      "epoch 25 | loss: 0.0     |  0:00:00s\n",
      "epoch 26 | loss: 0.0     |  0:00:00s\n",
      "epoch 27 | loss: 0.0     |  0:00:00s\n",
      "epoch 28 | loss: 0.0     |  0:00:00s\n",
      "epoch 29 | loss: 0.0     |  0:00:00s\n",
      "epoch 30 | loss: 0.0     |  0:00:00s\n",
      "epoch 31 | loss: 0.0     |  0:00:00s\n",
      "epoch 32 | loss: 0.0     |  0:00:00s\n",
      "epoch 33 | loss: 0.0     |  0:00:00s\n",
      "epoch 34 | loss: 0.0     |  0:00:00s\n",
      "epoch 35 | loss: 0.0     |  0:00:00s\n",
      "epoch 36 | loss: 0.0     |  0:00:00s\n",
      "epoch 37 | loss: 0.0     |  0:00:00s\n",
      "epoch 38 | loss: 0.0     |  0:00:00s\n",
      "epoch 39 | loss: 0.0     |  0:00:00s\n",
      "epoch 40 | loss: 0.0     |  0:00:00s\n",
      "epoch 41 | loss: 0.0     |  0:00:00s\n",
      "epoch 42 | loss: 0.0     |  0:00:00s\n",
      "epoch 43 | loss: 0.0     |  0:00:00s\n",
      "epoch 44 | loss: 0.0     |  0:00:00s\n",
      "epoch 45 | loss: 0.0     |  0:00:00s\n",
      "epoch 46 | loss: 0.0     |  0:00:00s\n",
      "epoch 47 | loss: 0.0     |  0:00:00s\n",
      "epoch 48 | loss: 0.0     |  0:00:00s\n",
      "epoch 49 | loss: 0.0     |  0:00:00s\n",
      "epoch 50 | loss: 0.0     |  0:00:00s\n",
      "epoch 51 | loss: 0.0     |  0:00:00s\n",
      "epoch 52 | loss: 0.0     |  0:00:00s\n",
      "epoch 53 | loss: 0.0     |  0:00:00s\n",
      "epoch 54 | loss: 0.0     |  0:00:00s\n",
      "epoch 55 | loss: 0.0     |  0:00:00s\n",
      "epoch 56 | loss: 0.0     |  0:00:00s\n",
      "epoch 57 | loss: 0.0     |  0:00:00s\n",
      "epoch 58 | loss: 0.0     |  0:00:00s\n",
      "epoch 59 | loss: 0.0     |  0:00:00s\n",
      "epoch 60 | loss: 0.0     |  0:00:00s\n",
      "epoch 61 | loss: 0.0     |  0:00:00s\n",
      "epoch 62 | loss: 0.0     |  0:00:00s\n",
      "epoch 63 | loss: 0.0     |  0:00:00s\n",
      "epoch 64 | loss: 0.0     |  0:00:00s\n",
      "epoch 65 | loss: 0.0     |  0:00:00s\n",
      "epoch 66 | loss: 0.0     |  0:00:00s\n",
      "epoch 67 | loss: 0.0     |  0:00:00s\n",
      "epoch 68 | loss: 0.0     |  0:00:00s\n",
      "epoch 69 | loss: 0.0     |  0:00:00s\n",
      "epoch 70 | loss: 0.0     |  0:00:00s\n",
      "epoch 71 | loss: 0.0     |  0:00:00s\n",
      "epoch 72 | loss: 0.0     |  0:00:00s\n",
      "epoch 73 | loss: 0.0     |  0:00:00s\n",
      "epoch 74 | loss: 0.0     |  0:00:00s\n",
      "epoch 75 | loss: 0.0     |  0:00:00s\n",
      "epoch 76 | loss: 0.0     |  0:00:00s\n",
      "epoch 77 | loss: 0.0     |  0:00:00s\n",
      "epoch 78 | loss: 0.0     |  0:00:00s\n",
      "epoch 79 | loss: 0.0     |  0:00:00s\n",
      "epoch 80 | loss: 0.0     |  0:00:00s\n",
      "epoch 81 | loss: 0.0     |  0:00:00s\n",
      "epoch 82 | loss: 0.0     |  0:00:00s\n",
      "epoch 83 | loss: 0.0     |  0:00:00s\n",
      "epoch 84 | loss: 0.0     |  0:00:00s\n",
      "epoch 85 | loss: 0.0     |  0:00:00s\n",
      "epoch 86 | loss: 0.0     |  0:00:00s\n",
      "epoch 87 | loss: 0.0     |  0:00:00s\n",
      "epoch 88 | loss: 0.0     |  0:00:00s\n",
      "epoch 89 | loss: 0.0     |  0:00:00s\n",
      "epoch 90 | loss: 0.0     |  0:00:00s\n",
      "epoch 91 | loss: 0.0     |  0:00:00s\n",
      "epoch 92 | loss: 0.0     |  0:00:00s\n",
      "epoch 93 | loss: 0.0     |  0:00:00s\n",
      "epoch 94 | loss: 0.0     |  0:00:00s\n",
      "epoch 95 | loss: 0.0     |  0:00:00s\n",
      "epoch 96 | loss: 0.0     |  0:00:00s\n",
      "epoch 97 | loss: 0.0     |  0:00:00s\n",
      "epoch 98 | loss: 0.0     |  0:00:00s\n",
      "epoch 99 | loss: 0.0     |  0:00:00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TabNetRegressor()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_epochs = 50\n",
    "\n",
    "aug = RegressionSMOTE(p=0.2)\n",
    "\n",
    "hyper_params = {\n",
    "    # 'eval_name':['train'],\n",
    "    'eval_metric':'rmse',\n",
    "    'max_epochs':max_epochs,\n",
    "    'patience':50,\n",
    "    'batch_size':1024,\n",
    "    # 'virtual_batch_size':[128],\n",
    "    'num_workers':0,\n",
    "    'drop_last':False,\n",
    "    'augmentations':aug,\n",
    "}\n",
    "\n",
    "\n",
    "model = TabNetRegressor(params=hyper_params)\n",
    "model.fit(X=x_train_tf.numpy(), y=y_train_tf.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10531056]\n",
      " [1.6712388 ]\n",
      " [0.16164011]\n",
      " [0.27864388]\n",
      " [0.5766951 ]\n",
      " [0.13512613]\n",
      " [0.10344587]\n",
      " [0.21447995]\n",
      " [0.559803  ]\n",
      " [0.2035209 ]\n",
      " [1.2294552 ]\n",
      " [1.2972308 ]\n",
      " [1.1885086 ]\n",
      " [0.09292021]\n",
      " [0.9523057 ]\n",
      " [0.39670974]\n",
      " [0.4737239 ]\n",
      " [1.6517028 ]\n",
      " [1.1128927 ]\n",
      " [1.236676  ]\n",
      " [0.24214111]\n",
      " [1.1023966 ]\n",
      " [0.25725403]\n",
      " [0.8908459 ]\n",
      " [1.1137012 ]\n",
      " [0.31928736]\n",
      " [0.3754837 ]\n",
      " [0.40251297]\n",
      " [0.9999148 ]\n",
      " [0.5806534 ]\n",
      " [0.41247594]\n",
      " [0.44697523]\n",
      " [0.3289414 ]\n",
      " [0.5440183 ]\n",
      " [0.06195755]\n",
      " [1.0988681 ]\n",
      " [0.84630615]\n",
      " [1.2498342 ]\n",
      " [0.12533203]\n",
      " [0.18557733]\n",
      " [0.47134036]\n",
      " [0.6393258 ]\n",
      " [0.8718143 ]\n",
      " [0.36211267]\n",
      " [0.01490778]\n",
      " [0.1862408 ]\n",
      " [1.213487  ]\n",
      " [0.43914345]\n",
      " [0.17036356]\n",
      " [0.6017263 ]\n",
      " [0.62276787]\n",
      " [0.1897778 ]\n",
      " [0.09831218]\n",
      " [1.1257963 ]\n",
      " [0.2679576 ]\n",
      " [0.62344635]\n",
      " [1.1100178 ]\n",
      " [0.1118616 ]\n",
      " [0.47669685]\n",
      " [0.4003078 ]\n",
      " [0.36725605]\n",
      " [0.6985779 ]\n",
      " [0.85881925]\n",
      " [1.2867513 ]\n",
      " [0.15071616]\n",
      " [0.96238554]\n",
      " [0.4583919 ]\n",
      " [1.1677942 ]\n",
      " [0.41834792]\n",
      " [0.26871103]\n",
      " [0.97614974]\n",
      " [0.5092205 ]\n",
      " [0.32600707]\n",
      " [0.7811117 ]\n",
      " [0.153285  ]\n",
      " [0.8178463 ]\n",
      " [0.6106038 ]\n",
      " [1.1054039 ]\n",
      " [0.5402708 ]\n",
      " [0.41079   ]\n",
      " [0.45302728]]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x_test.to_numpy())\n",
    "\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n",
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.0     |  0:00:00s\n",
      "epoch 1  | loss: 0.0     |  0:00:00s\n",
      "epoch 2  | loss: 0.0     |  0:00:00s\n",
      "epoch 3  | loss: 0.0     |  0:00:00s\n",
      "epoch 4  | loss: 0.0     |  0:00:00s\n",
      "epoch 5  | loss: 0.0     |  0:00:00s\n",
      "epoch 6  | loss: 0.0     |  0:00:00s\n",
      "epoch 7  | loss: 0.0     |  0:00:00s\n",
      "epoch 8  | loss: 0.0     |  0:00:00s\n",
      "epoch 9  | loss: 0.0     |  0:00:00s\n",
      "epoch 10 | loss: 0.0     |  0:00:00s\n",
      "epoch 11 | loss: 0.0     |  0:00:00s\n",
      "epoch 12 | loss: 0.0     |  0:00:00s\n",
      "epoch 13 | loss: 0.0     |  0:00:00s\n",
      "epoch 14 | loss: 0.0     |  0:00:00s\n",
      "epoch 15 | loss: 0.0     |  0:00:00s\n",
      "epoch 16 | loss: 0.0     |  0:00:00s\n",
      "epoch 17 | loss: 0.0     |  0:00:00s\n",
      "epoch 18 | loss: 0.0     |  0:00:00s\n",
      "epoch 19 | loss: 0.0     |  0:00:00s\n",
      "epoch 20 | loss: 0.0     |  0:00:00s\n",
      "epoch 21 | loss: 0.0     |  0:00:00s\n",
      "epoch 22 | loss: 0.0     |  0:00:00s\n",
      "epoch 23 | loss: 0.0     |  0:00:00s\n",
      "epoch 24 | loss: 0.0     |  0:00:00s\n",
      "epoch 25 | loss: 0.0     |  0:00:00s\n",
      "epoch 26 | loss: 0.0     |  0:00:00s\n",
      "epoch 27 | loss: 0.0     |  0:00:00s\n",
      "epoch 28 | loss: 0.0     |  0:00:00s\n",
      "epoch 29 | loss: 0.0     |  0:00:00s\n",
      "epoch 30 | loss: 0.0     |  0:00:00s\n",
      "epoch 31 | loss: 0.0     |  0:00:00s\n",
      "epoch 32 | loss: 0.0     |  0:00:00s\n",
      "epoch 33 | loss: 0.0     |  0:00:00s\n",
      "epoch 34 | loss: 0.0     |  0:00:00s\n",
      "epoch 35 | loss: 0.0     |  0:00:00s\n",
      "epoch 36 | loss: 0.0     |  0:00:00s\n",
      "epoch 37 | loss: 0.0     |  0:00:00s\n",
      "epoch 38 | loss: 0.0     |  0:00:00s\n",
      "epoch 39 | loss: 0.0     |  0:00:00s\n",
      "epoch 40 | loss: 0.0     |  0:00:00s\n",
      "epoch 41 | loss: 0.0     |  0:00:00s\n",
      "epoch 42 | loss: 0.0     |  0:00:00s\n",
      "epoch 43 | loss: 0.0     |  0:00:00s\n",
      "epoch 44 | loss: 0.0     |  0:00:00s\n",
      "epoch 45 | loss: 0.0     |  0:00:00s\n",
      "epoch 46 | loss: 0.0     |  0:00:00s\n",
      "epoch 47 | loss: 0.0     |  0:00:00s\n",
      "epoch 48 | loss: 0.0     |  0:00:00s\n",
      "epoch 49 | loss: 0.0     |  0:00:00s\n",
      "epoch 50 | loss: 0.0     |  0:00:00s\n",
      "epoch 51 | loss: 0.0     |  0:00:00s\n",
      "epoch 52 | loss: 0.0     |  0:00:00s\n",
      "epoch 53 | loss: 0.0     |  0:00:00s\n",
      "epoch 54 | loss: 0.0     |  0:00:00s\n",
      "epoch 55 | loss: 0.0     |  0:00:00s\n",
      "epoch 56 | loss: 0.0     |  0:00:00s\n",
      "epoch 57 | loss: 0.0     |  0:00:00s\n",
      "epoch 58 | loss: 0.0     |  0:00:00s\n",
      "epoch 59 | loss: 0.0     |  0:00:00s\n",
      "epoch 60 | loss: 0.0     |  0:00:00s\n",
      "epoch 61 | loss: 0.0     |  0:00:00s\n",
      "epoch 62 | loss: 0.0     |  0:00:00s\n",
      "epoch 63 | loss: 0.0     |  0:00:00s\n",
      "epoch 64 | loss: 0.0     |  0:00:00s\n",
      "epoch 65 | loss: 0.0     |  0:00:00s\n",
      "epoch 66 | loss: 0.0     |  0:00:00s\n",
      "epoch 67 | loss: 0.0     |  0:00:00s\n",
      "epoch 68 | loss: 0.0     |  0:00:00s\n",
      "epoch 69 | loss: 0.0     |  0:00:00s\n",
      "epoch 70 | loss: 0.0     |  0:00:00s\n",
      "epoch 71 | loss: 0.0     |  0:00:00s\n",
      "epoch 72 | loss: 0.0     |  0:00:00s\n",
      "epoch 73 | loss: 0.0     |  0:00:00s\n",
      "epoch 74 | loss: 0.0     |  0:00:00s\n",
      "epoch 75 | loss: 0.0     |  0:00:00s\n",
      "epoch 76 | loss: 0.0     |  0:00:00s\n",
      "epoch 77 | loss: 0.0     |  0:00:00s\n",
      "epoch 78 | loss: 0.0     |  0:00:00s\n",
      "epoch 79 | loss: 0.0     |  0:00:00s\n",
      "epoch 80 | loss: 0.0     |  0:00:00s\n",
      "epoch 81 | loss: 0.0     |  0:00:00s\n",
      "epoch 82 | loss: 0.0     |  0:00:00s\n",
      "epoch 83 | loss: 0.0     |  0:00:00s\n",
      "epoch 84 | loss: 0.0     |  0:00:00s\n",
      "epoch 85 | loss: 0.0     |  0:00:00s\n",
      "epoch 86 | loss: 0.0     |  0:00:00s\n",
      "epoch 87 | loss: 0.0     |  0:00:00s\n",
      "epoch 88 | loss: 0.0     |  0:00:00s\n",
      "epoch 89 | loss: 0.0     |  0:00:00s\n",
      "epoch 90 | loss: 0.0     |  0:00:00s\n",
      "epoch 91 | loss: 0.0     |  0:00:00s\n",
      "epoch 92 | loss: 0.0     |  0:00:00s\n",
      "epoch 93 | loss: 0.0     |  0:00:00s\n",
      "epoch 94 | loss: 0.0     |  0:00:00s\n",
      "epoch 95 | loss: 0.0     |  0:00:00s\n",
      "epoch 96 | loss: 0.0     |  0:00:00s\n",
      "epoch 97 | loss: 0.0     |  0:00:00s\n",
      "epoch 98 | loss: 0.0     |  0:00:00s\n",
      "epoch 99 | loss: 0.0     |  0:00:00s\n"
     ]
    }
   ],
   "source": [
    "hyper_params_grid = {\n",
    "    # 'eval_name':['train'],\n",
    "    'eval_metric':['rmse'],\n",
    "    'max_epochs':[max_epochs],\n",
    "    'patience':[50, 100],\n",
    "    'batch_size':[1024],\n",
    "    # 'virtual_batch_size':[128],\n",
    "    'num_workers':[0, 1],\n",
    "    'drop_last':[False],\n",
    "    'augmentations':[aug],\n",
    "}\n",
    "\n",
    "\n",
    "# Call GridSearchCV()\n",
    "model_cv = RandomizedSearchCV(\n",
    "    estimator = TabNetRegressor(),\n",
    "    param_distributions = hyper_params_grid,\n",
    "    n_iter=10,\n",
    "    scoring= 'r2',\n",
    "    cv = folds,\n",
    "    verbose = 1,\n",
    "    return_train_score=True,\n",
    "    n_jobs = -1,\n",
    "    # refit = True\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "best_model = model_cv.fit(X=x_train_tf.numpy(), y=y_train_tf.numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patience': 50, 'num_workers': 0, 'max_epochs': 50, 'eval_metric': 'rmse', 'drop_last': False, 'batch_size': 1024, 'augmentations': <pytorch_tabnet.augmentations.RegressionSMOTE object at 0x129e54710>}\n"
     ]
    }
   ],
   "source": [
    "print(model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': KFold(n_splits=10, random_state=100, shuffle=True),\n",
       " 'error_score': nan,\n",
       " 'estimator': TabNetRegressor(),\n",
       " 'n_iter': 10,\n",
       " 'n_jobs': -1,\n",
       " 'param_distributions': {'eval_metric': ['rmse'],\n",
       "  'max_epochs': [50],\n",
       "  'patience': [50, 100],\n",
       "  'batch_size': [1024],\n",
       "  'num_workers': [0, 1],\n",
       "  'drop_last': [False],\n",
       "  'augmentations': [<pytorch_tabnet.augmentations.RegressionSMOTE at 0x129e54710>]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'random_state': None,\n",
       " 'refit': True,\n",
       " 'return_train_score': True,\n",
       " 'scoring': 'r2',\n",
       " 'verbose': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.0     |  0:00:00s\n",
      "epoch 1  | loss: 0.0     |  0:00:00s\n",
      "epoch 2  | loss: 0.0     |  0:00:00s\n",
      "epoch 3  | loss: 0.0     |  0:00:00s\n",
      "epoch 4  | loss: 0.0     |  0:00:00s\n",
      "epoch 5  | loss: 0.0     |  0:00:00s\n",
      "epoch 6  | loss: 0.0     |  0:00:00s\n",
      "epoch 7  | loss: 0.0     |  0:00:00s\n",
      "epoch 8  | loss: 0.0     |  0:00:00s\n",
      "epoch 9  | loss: 0.0     |  0:00:00s\n",
      "epoch 10 | loss: 0.0     |  0:00:00s\n",
      "epoch 11 | loss: 0.0     |  0:00:00s\n",
      "epoch 12 | loss: 0.0     |  0:00:00s\n",
      "epoch 13 | loss: 0.0     |  0:00:00s\n",
      "epoch 14 | loss: 0.0     |  0:00:00s\n",
      "epoch 15 | loss: 0.0     |  0:00:00s\n",
      "epoch 16 | loss: 0.0     |  0:00:00s\n",
      "epoch 17 | loss: 0.0     |  0:00:00s\n",
      "epoch 18 | loss: 0.0     |  0:00:00s\n",
      "epoch 19 | loss: 0.0     |  0:00:00s\n",
      "epoch 20 | loss: 0.0     |  0:00:00s\n",
      "epoch 21 | loss: 0.0     |  0:00:00s\n",
      "epoch 22 | loss: 0.0     |  0:00:00s\n",
      "epoch 23 | loss: 0.0     |  0:00:00s\n",
      "epoch 24 | loss: 0.0     |  0:00:00s\n",
      "epoch 25 | loss: 0.0     |  0:00:00s\n",
      "epoch 26 | loss: 0.0     |  0:00:00s\n",
      "epoch 27 | loss: 0.0     |  0:00:00s\n",
      "epoch 28 | loss: 0.0     |  0:00:00s\n",
      "epoch 29 | loss: 0.0     |  0:00:00s\n",
      "epoch 30 | loss: 0.0     |  0:00:00s\n",
      "epoch 31 | loss: 0.0     |  0:00:00s\n",
      "epoch 32 | loss: 0.0     |  0:00:00s\n",
      "epoch 33 | loss: 0.0     |  0:00:00s\n",
      "epoch 34 | loss: 0.0     |  0:00:00s\n",
      "epoch 35 | loss: 0.0     |  0:00:00s\n",
      "epoch 36 | loss: 0.0     |  0:00:00s\n",
      "epoch 37 | loss: 0.0     |  0:00:00s\n",
      "epoch 38 | loss: 0.0     |  0:00:00s\n",
      "epoch 39 | loss: 0.0     |  0:00:00s\n",
      "epoch 40 | loss: 0.0     |  0:00:00s\n",
      "epoch 41 | loss: 0.0     |  0:00:00s\n",
      "epoch 42 | loss: 0.0     |  0:00:00s\n",
      "epoch 43 | loss: 0.0     |  0:00:00s\n",
      "epoch 44 | loss: 0.0     |  0:00:00s\n",
      "epoch 45 | loss: 0.0     |  0:00:00s\n",
      "epoch 46 | loss: 0.0     |  0:00:00s\n",
      "epoch 47 | loss: 0.0     |  0:00:00s\n",
      "epoch 48 | loss: 0.0     |  0:00:00s\n",
      "epoch 49 | loss: 0.0     |  0:00:00s\n",
      "epoch 50 | loss: 0.0     |  0:00:00s\n",
      "epoch 51 | loss: 0.0     |  0:00:00s\n",
      "epoch 52 | loss: 0.0     |  0:00:00s\n",
      "epoch 53 | loss: 0.0     |  0:00:00s\n",
      "epoch 54 | loss: 0.0     |  0:00:00s\n",
      "epoch 55 | loss: 0.0     |  0:00:00s\n",
      "epoch 56 | loss: 0.0     |  0:00:00s\n",
      "epoch 57 | loss: 0.0     |  0:00:00s\n",
      "epoch 58 | loss: 0.0     |  0:00:00s\n",
      "epoch 59 | loss: 0.0     |  0:00:00s\n",
      "epoch 60 | loss: 0.0     |  0:00:00s\n",
      "epoch 61 | loss: 0.0     |  0:00:00s\n",
      "epoch 62 | loss: 0.0     |  0:00:00s\n",
      "epoch 63 | loss: 0.0     |  0:00:00s\n",
      "epoch 64 | loss: 0.0     |  0:00:00s\n",
      "epoch 65 | loss: 0.0     |  0:00:00s\n",
      "epoch 66 | loss: 0.0     |  0:00:00s\n",
      "epoch 67 | loss: 0.0     |  0:00:00s\n",
      "epoch 68 | loss: 0.0     |  0:00:00s\n",
      "epoch 69 | loss: 0.0     |  0:00:00s\n",
      "epoch 70 | loss: 0.0     |  0:00:00s\n",
      "epoch 71 | loss: 0.0     |  0:00:00s\n",
      "epoch 72 | loss: 0.0     |  0:00:00s\n",
      "epoch 73 | loss: 0.0     |  0:00:00s\n",
      "epoch 74 | loss: 0.0     |  0:00:00s\n",
      "epoch 75 | loss: 0.0     |  0:00:00s\n",
      "epoch 76 | loss: 0.0     |  0:00:00s\n",
      "epoch 77 | loss: 0.0     |  0:00:00s\n",
      "epoch 78 | loss: 0.0     |  0:00:00s\n",
      "epoch 79 | loss: 0.0     |  0:00:00s\n",
      "epoch 80 | loss: 0.0     |  0:00:00s\n",
      "epoch 81 | loss: 0.0     |  0:00:00s\n",
      "epoch 82 | loss: 0.0     |  0:00:00s\n",
      "epoch 83 | loss: 0.0     |  0:00:00s\n",
      "epoch 84 | loss: 0.0     |  0:00:00s\n",
      "epoch 85 | loss: 0.0     |  0:00:00s\n",
      "epoch 86 | loss: 0.0     |  0:00:00s\n",
      "epoch 87 | loss: 0.0     |  0:00:00s\n",
      "epoch 88 | loss: 0.0     |  0:00:00s\n",
      "epoch 89 | loss: 0.0     |  0:00:00s\n",
      "epoch 90 | loss: 0.0     |  0:00:00s\n",
      "epoch 91 | loss: 0.0     |  0:00:00s\n",
      "epoch 92 | loss: 0.0     |  0:00:00s\n",
      "epoch 93 | loss: 0.0     |  0:00:00s\n",
      "epoch 94 | loss: 0.0     |  0:00:00s\n",
      "epoch 95 | loss: 0.0     |  0:00:00s\n",
      "epoch 96 | loss: 0.0     |  0:00:00s\n",
      "epoch 97 | loss: 0.0     |  0:00:00s\n",
      "epoch 98 | loss: 0.0     |  0:00:00s\n",
      "epoch 99 | loss: 0.0     |  0:00:00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 50\n",
    "\n",
    "aug = RegressionSMOTE(p=0.2)\n",
    "\n",
    "hyper_params = {\n",
    "    # 'eval_name':['train'],\n",
    "    'eval_metric':'rmse',\n",
    "    'max_epochs':max_epochs,\n",
    "    'patience':50,\n",
    "    'batch_size':1024,\n",
    "    # 'virtual_batch_size':[128],\n",
    "    'num_workers':0,\n",
    "    'drop_last':False,\n",
    "    'augmentations':aug,\n",
    "}\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "best_model = model_cv.fit(X=x_train_tf.numpy(), y=y_train_tf.numpy(), params=hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4381.92529|  0:00:00s\n",
      "epoch 1  | loss: 4477.31396|  0:00:00s\n",
      "epoch 2  | loss: 4332.4541|  0:00:00s\n",
      "epoch 3  | loss: 4335.12695|  0:00:00s\n",
      "epoch 4  | loss: 4434.16113|  0:00:00s\n",
      "epoch 5  | loss: 4293.05078|  0:00:00s\n",
      "epoch 6  | loss: 4295.91406|  0:00:00s\n",
      "epoch 7  | loss: 4278.11621|  0:00:00s\n",
      "epoch 8  | loss: 4191.25488|  0:00:00s\n",
      "epoch 9  | loss: 4115.03027|  0:00:00s\n",
      "epoch 10 | loss: 4070.47754|  0:00:00s\n",
      "epoch 11 | loss: 4045.5376|  0:00:00s\n",
      "epoch 12 | loss: 3953.68701|  0:00:00s\n",
      "epoch 13 | loss: 3957.26221|  0:00:00s\n",
      "epoch 14 | loss: 3819.87036|  0:00:00s\n",
      "epoch 15 | loss: 3798.51685|  0:00:01s\n",
      "epoch 16 | loss: 3733.75684|  0:00:01s\n",
      "epoch 17 | loss: 3757.92163|  0:00:01s\n",
      "epoch 18 | loss: 3634.28394|  0:00:01s\n",
      "epoch 19 | loss: 3530.59521|  0:00:01s\n",
      "epoch 20 | loss: 3434.26465|  0:00:01s\n",
      "epoch 21 | loss: 3369.76074|  0:00:01s\n",
      "epoch 22 | loss: 3295.0564|  0:00:01s\n",
      "epoch 23 | loss: 3116.08594|  0:00:01s\n",
      "epoch 24 | loss: 3115.02222|  0:00:01s\n",
      "epoch 25 | loss: 3031.24194|  0:00:01s\n",
      "epoch 26 | loss: 2838.21899|  0:00:01s\n",
      "epoch 27 | loss: 2822.99268|  0:00:01s\n",
      "epoch 28 | loss: 2678.71143|  0:00:01s\n",
      "epoch 29 | loss: 2586.52051|  0:00:01s\n",
      "epoch 30 | loss: 2505.29785|  0:00:01s\n",
      "epoch 31 | loss: 2409.03516|  0:00:01s\n",
      "epoch 32 | loss: 2302.44946|  0:00:01s\n",
      "epoch 33 | loss: 2234.01196|  0:00:01s\n",
      "epoch 34 | loss: 2138.15088|  0:00:01s\n",
      "epoch 35 | loss: 2054.95142|  0:00:01s\n",
      "epoch 36 | loss: 1947.69434|  0:00:02s\n",
      "epoch 37 | loss: 1749.66602|  0:00:02s\n",
      "epoch 38 | loss: 1760.52649|  0:00:02s\n",
      "epoch 39 | loss: 1600.01794|  0:00:02s\n",
      "epoch 40 | loss: 1548.65356|  0:00:02s\n",
      "epoch 41 | loss: 1480.06531|  0:00:02s\n",
      "epoch 42 | loss: 1365.79846|  0:00:02s\n",
      "epoch 43 | loss: 1333.87903|  0:00:02s\n",
      "epoch 44 | loss: 1231.21082|  0:00:02s\n",
      "epoch 45 | loss: 1150.36133|  0:00:02s\n",
      "epoch 46 | loss: 1087.73279|  0:00:02s\n",
      "epoch 47 | loss: 1007.54681|  0:00:02s\n",
      "epoch 48 | loss: 944.4469|  0:00:02s\n",
      "epoch 49 | loss: 890.88171|  0:00:02s\n"
     ]
    }
   ],
   "source": [
    "clf = TN()\n",
    "\n",
    "aug = RegressionSMOTE(p=0.2)\n",
    "\n",
    "clf.fit(X_train=x_train_tf.numpy(), y_train=y_train_tf.numpy(),\n",
    "    # eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    # eval_name=['train', 'valid'],\n",
    "    eval_metric=['rmsle', 'mae', 'rmse', 'mse'],\n",
    "    max_epochs=max_epochs,\n",
    "    patience=50,\n",
    "    batch_size=1024, virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    augmentations=aug, #aug\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
