{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor as TN\n",
    "from pytorch_tabnet.augmentations import RegressionSMOTE\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "\n",
    "# Utils functions\n",
    "from utils.utils import read_datasets, kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = read_datasets(\n",
    "    'x_train.csv',\n",
    "    'x_test.csv',\n",
    "    'y_train.csv',\n",
    "    'y_test.csv'\n",
    ")\n",
    "\n",
    "\n",
    "# convert data to tensor\n",
    "x_train_tf = torch.tensor(x_train.values.astype(np.float64)) \n",
    "y_train_tf = torch.tensor(y_train.values)\n",
    "\n",
    "x_test_tf = torch.tensor(x_test.values.astype(np.float64)) \n",
    "y_test_tf = torch.tensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = kfold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabNetRegressor(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def __init__(self, params={}):\n",
    "        super(BaseEstimator, self).__init__()\n",
    "        super(RegressorMixin, self).__init__()\n",
    "        self.tabnet = TN()\n",
    "        self.params = params\n",
    "\n",
    "    def fit(self, X, y=None, params={}):\n",
    "        if params != {}:\n",
    "            self.params = params\n",
    "        self.tabnet.fit(X, y, **self.params)\n",
    "\n",
    "        print(self.params)\n",
    "        \n",
    "        return self\n",
    "        # return self.tabnet.fit(check_array(X), np.array(y).reshape(-1, 1))\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        preds = self.tabnet.predict(X)\n",
    "        return preds\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return self.params\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for value, key in params.items():\n",
    "            self.key = value\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4381.92529|  0:00:00s\n",
      "epoch 1  | loss: 4477.31396|  0:00:00s\n",
      "epoch 2  | loss: 4332.4541|  0:00:00s\n",
      "epoch 3  | loss: 4335.12695|  0:00:00s\n",
      "epoch 4  | loss: 4434.16113|  0:00:00s\n",
      "epoch 5  | loss: 4293.05078|  0:00:00s\n",
      "epoch 6  | loss: 4295.91406|  0:00:00s\n",
      "epoch 7  | loss: 4278.11621|  0:00:00s\n",
      "epoch 8  | loss: 4191.25488|  0:00:00s\n",
      "epoch 9  | loss: 4115.03027|  0:00:00s\n",
      "epoch 10 | loss: 4070.47754|  0:00:00s\n",
      "epoch 11 | loss: 4045.5376|  0:00:00s\n",
      "epoch 12 | loss: 3953.68701|  0:00:00s\n",
      "epoch 13 | loss: 3957.26221|  0:00:00s\n",
      "epoch 14 | loss: 3819.87036|  0:00:00s\n",
      "epoch 15 | loss: 3798.51685|  0:00:00s\n",
      "epoch 16 | loss: 3733.75684|  0:00:00s\n",
      "epoch 17 | loss: 3757.92163|  0:00:00s\n",
      "epoch 18 | loss: 3634.28394|  0:00:00s\n",
      "epoch 19 | loss: 3530.59521|  0:00:01s\n",
      "epoch 20 | loss: 3434.26465|  0:00:01s\n",
      "epoch 21 | loss: 3369.76074|  0:00:01s\n",
      "epoch 22 | loss: 3295.0564|  0:00:01s\n",
      "epoch 23 | loss: 3116.08594|  0:00:01s\n",
      "epoch 24 | loss: 3115.02222|  0:00:01s\n",
      "epoch 25 | loss: 3031.24194|  0:00:01s\n",
      "epoch 26 | loss: 2838.21899|  0:00:01s\n",
      "epoch 27 | loss: 2822.99268|  0:00:01s\n",
      "epoch 28 | loss: 2678.71143|  0:00:01s\n",
      "epoch 29 | loss: 2586.52051|  0:00:01s\n",
      "epoch 30 | loss: 2505.29785|  0:00:01s\n",
      "epoch 31 | loss: 2409.03516|  0:00:01s\n",
      "epoch 32 | loss: 2302.44946|  0:00:01s\n",
      "epoch 33 | loss: 2234.01196|  0:00:01s\n",
      "epoch 34 | loss: 2138.15088|  0:00:01s\n",
      "epoch 35 | loss: 2054.95142|  0:00:01s\n",
      "epoch 36 | loss: 1947.69434|  0:00:01s\n",
      "epoch 37 | loss: 1749.66602|  0:00:01s\n",
      "epoch 38 | loss: 1760.52649|  0:00:01s\n",
      "epoch 39 | loss: 1600.01794|  0:00:01s\n",
      "epoch 40 | loss: 1548.65356|  0:00:01s\n",
      "epoch 41 | loss: 1480.06531|  0:00:01s\n",
      "epoch 42 | loss: 1365.79846|  0:00:01s\n",
      "epoch 43 | loss: 1333.87903|  0:00:01s\n",
      "epoch 44 | loss: 1231.21082|  0:00:01s\n",
      "epoch 45 | loss: 1150.36133|  0:00:01s\n",
      "epoch 46 | loss: 1087.73279|  0:00:02s\n",
      "epoch 47 | loss: 1007.54681|  0:00:02s\n",
      "epoch 48 | loss: 944.4469|  0:00:02s\n",
      "epoch 49 | loss: 890.88171|  0:00:02s\n",
      "{'eval_metric': 'rmse', 'max_epochs': 50, 'patience': 50, 'batch_size': 1024, 'num_workers': 0, 'drop_last': False, 'augmentations': <pytorch_tabnet.augmentations.RegressionSMOTE object at 0x129b70390>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TabNetRegressor(augmentations=<pytorch_tabnet.augmentations.RegressionSMOTE object at 0x129b70390>,\n",
       "                batch_size=1024, drop_last=False, eval_metric='rmse',\n",
       "                max_epochs=50, num_workers=0, patience=50)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_epochs = 50\n",
    "\n",
    "aug = RegressionSMOTE(p=0.2)\n",
    "\n",
    "hyper_params = {\n",
    "    # 'eval_name':['train'],\n",
    "    'eval_metric':'rmse',\n",
    "    'max_epochs':max_epochs,\n",
    "    'patience':50,\n",
    "    'batch_size':1024,\n",
    "    # 'virtual_batch_size':[128],\n",
    "    'num_workers':0,\n",
    "    'drop_last':False,\n",
    "    'augmentations':aug,\n",
    "}\n",
    "\n",
    "\n",
    "model = TabNetRegressor(params=hyper_params)\n",
    "model.fit(X=x_train_tf.numpy(), y=y_train_tf.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[60.23117 ]\n",
      " [54.39115 ]\n",
      " [63.43062 ]\n",
      " [59.334133]\n",
      " [61.88777 ]\n",
      " [65.74707 ]\n",
      " [42.745224]\n",
      " [62.79294 ]\n",
      " [56.76098 ]\n",
      " [36.524616]\n",
      " [62.62951 ]\n",
      " [44.430782]\n",
      " [72.26399 ]\n",
      " [61.281578]\n",
      " [72.50192 ]\n",
      " [45.298374]\n",
      " [74.25104 ]\n",
      " [43.960014]\n",
      " [69.55649 ]\n",
      " [41.976913]\n",
      " [61.730988]\n",
      " [55.186615]\n",
      " [68.0451  ]\n",
      " [66.61631 ]\n",
      " [49.067535]\n",
      " [64.574135]\n",
      " [42.630863]\n",
      " [62.87755 ]\n",
      " [73.68086 ]\n",
      " [57.814617]\n",
      " [62.49225 ]\n",
      " [61.431683]\n",
      " [60.23233 ]\n",
      " [38.273087]\n",
      " [41.26091 ]\n",
      " [49.36937 ]\n",
      " [65.25845 ]\n",
      " [73.62394 ]\n",
      " [65.260414]\n",
      " [72.49123 ]\n",
      " [45.604733]\n",
      " [67.07146 ]\n",
      " [68.415535]\n",
      " [42.206444]\n",
      " [40.97438 ]\n",
      " [64.9309  ]\n",
      " [73.28914 ]\n",
      " [68.87916 ]\n",
      " [62.074036]\n",
      " [54.021873]\n",
      " [39.495018]\n",
      " [63.926907]\n",
      " [55.235878]\n",
      " [46.41667 ]\n",
      " [63.97428 ]\n",
      " [61.892952]\n",
      " [60.015575]\n",
      " [62.8506  ]\n",
      " [62.257042]\n",
      " [65.94771 ]\n",
      " [55.841896]\n",
      " [51.70161 ]\n",
      " [62.335552]\n",
      " [72.639465]\n",
      " [61.421883]\n",
      " [45.49151 ]\n",
      " [57.70807 ]\n",
      " [64.39366 ]\n",
      " [49.96189 ]\n",
      " [52.943813]\n",
      " [65.99477 ]\n",
      " [45.053802]\n",
      " [63.26612 ]\n",
      " [64.35472 ]\n",
      " [64.39198 ]\n",
      " [61.61534 ]\n",
      " [39.393383]\n",
      " [65.31154 ]\n",
      " [70.25133 ]\n",
      " [48.057068]\n",
      " [57.51619 ]]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x_test.to_numpy())\n",
    "\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.0     |  0:00:00s\n",
      "epoch 1  | loss: 0.0     |  0:00:00s\n",
      "epoch 2  | loss: 0.0     |  0:00:00s\n",
      "epoch 3  | loss: 0.0     |  0:00:00s\n",
      "epoch 4  | loss: 0.0     |  0:00:00s\n",
      "epoch 5  | loss: 0.0     |  0:00:00s\n",
      "epoch 6  | loss: 0.0     |  0:00:00s\n",
      "epoch 7  | loss: 0.0     |  0:00:00s\n",
      "epoch 8  | loss: 0.0     |  0:00:00s\n",
      "epoch 9  | loss: 0.0     |  0:00:00s\n",
      "epoch 10 | loss: 0.0     |  0:00:00s\n",
      "epoch 11 | loss: 0.0     |  0:00:00s\n",
      "epoch 12 | loss: 0.0     |  0:00:00s\n",
      "epoch 13 | loss: 0.0     |  0:00:00s\n",
      "epoch 14 | loss: 0.0     |  0:00:00s\n",
      "epoch 15 | loss: 0.0     |  0:00:00s\n",
      "epoch 16 | loss: 0.0     |  0:00:00s\n",
      "epoch 17 | loss: 0.0     |  0:00:00s\n",
      "epoch 18 | loss: 0.0     |  0:00:00s\n",
      "epoch 19 | loss: 0.0     |  0:00:00s\n",
      "epoch 20 | loss: 0.0     |  0:00:00s\n",
      "epoch 21 | loss: 0.0     |  0:00:00s\n",
      "epoch 22 | loss: 0.0     |  0:00:00s\n",
      "epoch 23 | loss: 0.0     |  0:00:00s\n",
      "epoch 24 | loss: 0.0     |  0:00:00s\n",
      "epoch 25 | loss: 0.0     |  0:00:00s\n",
      "epoch 26 | loss: 0.0     |  0:00:00s\n",
      "epoch 27 | loss: 0.0     |  0:00:00s\n",
      "epoch 28 | loss: 0.0     |  0:00:00s\n",
      "epoch 29 | loss: 0.0     |  0:00:00s\n",
      "epoch 30 | loss: 0.0     |  0:00:00s\n",
      "epoch 31 | loss: 0.0     |  0:00:00s\n",
      "epoch 32 | loss: 0.0     |  0:00:00s\n",
      "epoch 33 | loss: 0.0     |  0:00:00s\n",
      "epoch 34 | loss: 0.0     |  0:00:00s\n",
      "epoch 35 | loss: 0.0     |  0:00:00s\n",
      "epoch 36 | loss: 0.0     |  0:00:00s\n",
      "epoch 37 | loss: 0.0     |  0:00:00s\n",
      "epoch 38 | loss: 0.0     |  0:00:00s\n",
      "epoch 39 | loss: 0.0     |  0:00:00s\n",
      "epoch 40 | loss: 0.0     |  0:00:00s\n",
      "epoch 41 | loss: 0.0     |  0:00:00s\n",
      "epoch 42 | loss: 0.0     |  0:00:00s\n",
      "epoch 43 | loss: 0.0     |  0:00:00s\n",
      "epoch 44 | loss: 0.0     |  0:00:00s\n",
      "epoch 45 | loss: 0.0     |  0:00:00s\n",
      "epoch 46 | loss: 0.0     |  0:00:00s\n",
      "epoch 47 | loss: 0.0     |  0:00:00s\n",
      "epoch 48 | loss: 0.0     |  0:00:00s\n",
      "epoch 49 | loss: 0.0     |  0:00:00s\n",
      "epoch 50 | loss: 0.0     |  0:00:00s\n",
      "epoch 51 | loss: 0.0     |  0:00:00s\n",
      "epoch 52 | loss: 0.0     |  0:00:00s\n",
      "epoch 53 | loss: 0.0     |  0:00:00s\n",
      "epoch 54 | loss: 0.0     |  0:00:00s\n",
      "epoch 55 | loss: 0.0     |  0:00:00s\n",
      "epoch 56 | loss: 0.0     |  0:00:00s\n",
      "epoch 57 | loss: 0.0     |  0:00:00s\n",
      "epoch 58 | loss: 0.0     |  0:00:00s\n",
      "epoch 59 | loss: 0.0     |  0:00:00s\n",
      "epoch 60 | loss: 0.0     |  0:00:00s\n",
      "epoch 61 | loss: 0.0     |  0:00:00s\n",
      "epoch 62 | loss: 0.0     |  0:00:00s\n",
      "epoch 63 | loss: 0.0     |  0:00:00s\n",
      "epoch 64 | loss: 0.0     |  0:00:00s\n",
      "epoch 65 | loss: 0.0     |  0:00:00s\n",
      "epoch 66 | loss: 0.0     |  0:00:00s\n",
      "epoch 67 | loss: 0.0     |  0:00:00s\n",
      "epoch 68 | loss: 0.0     |  0:00:00s\n",
      "epoch 69 | loss: 0.0     |  0:00:00s\n",
      "epoch 70 | loss: 0.0     |  0:00:00s\n",
      "epoch 71 | loss: 0.0     |  0:00:00s\n",
      "epoch 72 | loss: 0.0     |  0:00:00s\n",
      "epoch 73 | loss: 0.0     |  0:00:00s\n",
      "epoch 74 | loss: 0.0     |  0:00:00s\n",
      "epoch 75 | loss: 0.0     |  0:00:00s\n",
      "epoch 76 | loss: 0.0     |  0:00:00s\n",
      "epoch 77 | loss: 0.0     |  0:00:00s\n",
      "epoch 78 | loss: 0.0     |  0:00:00s\n",
      "epoch 79 | loss: 0.0     |  0:00:00s\n",
      "epoch 80 | loss: 0.0     |  0:00:00s\n",
      "epoch 81 | loss: 0.0     |  0:00:00s\n",
      "epoch 82 | loss: 0.0     |  0:00:00s\n",
      "epoch 83 | loss: 0.0     |  0:00:00s\n",
      "epoch 84 | loss: 0.0     |  0:00:00s\n",
      "epoch 85 | loss: 0.0     |  0:00:00s\n",
      "epoch 86 | loss: 0.0     |  0:00:00s\n",
      "epoch 87 | loss: 0.0     |  0:00:00s\n",
      "epoch 88 | loss: 0.0     |  0:00:00s\n",
      "epoch 89 | loss: 0.0     |  0:00:00s\n",
      "epoch 90 | loss: 0.0     |  0:00:00s\n",
      "epoch 91 | loss: 0.0     |  0:00:00s\n",
      "epoch 92 | loss: 0.0     |  0:00:00s\n",
      "epoch 93 | loss: 0.0     |  0:00:00s\n",
      "epoch 94 | loss: 0.0     |  0:00:00s\n",
      "epoch 95 | loss: 0.0     |  0:00:00s\n",
      "epoch 96 | loss: 0.0     |  0:00:00s\n",
      "epoch 97 | loss: 0.0     |  0:00:00s\n",
      "epoch 98 | loss: 0.0     |  0:00:00s\n",
      "epoch 99 | loss: 0.0     |  0:00:00s\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "hyper_params_grid = {\n",
    "    # 'eval_name':['train'],\n",
    "    'eval_metric':['rmse'],\n",
    "    'max_epochs':[max_epochs],\n",
    "    'patience':[50, 100, 150],\n",
    "    'batch_size':[1024, 64],\n",
    "    # 'virtual_batch_size':[128],\n",
    "    'num_workers':[0, 1],\n",
    "    'drop_last':[False],\n",
    "    'augmentations':[aug],\n",
    "}\n",
    "\n",
    "\n",
    "# Call GridSearchCV()\n",
    "model_cv = RandomizedSearchCV(\n",
    "    estimator = TabNetRegressor(),\n",
    "    param_distributions = hyper_params_grid,\n",
    "    n_iter=5,\n",
    "    scoring= 'r2',\n",
    "    cv = folds,\n",
    "    verbose = 1,\n",
    "    return_train_score=True,\n",
    "    n_jobs = -1,\n",
    "    # refit = True\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "best_model = model_cv.fit(X=x_train_tf.numpy(), y=y_train_tf.numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patience': 50, 'num_workers': 1, 'max_epochs': 50, 'eval_metric': 'rmse', 'drop_last': False, 'batch_size': 1024, 'augmentations': <pytorch_tabnet.augmentations.RegressionSMOTE object at 0x129b70390>}\n"
     ]
    }
   ],
   "source": [
    "print(model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': KFold(n_splits=10, random_state=100, shuffle=True),\n",
       " 'error_score': nan,\n",
       " 'estimator': TabNetRegressor(),\n",
       " 'n_iter': 5,\n",
       " 'n_jobs': -1,\n",
       " 'param_distributions': {'eval_metric': ['rmse'],\n",
       "  'max_epochs': [50],\n",
       "  'patience': [50, 100, 150],\n",
       "  'batch_size': [1024, 64],\n",
       "  'num_workers': [0, 1],\n",
       "  'drop_last': [False],\n",
       "  'augmentations': [<pytorch_tabnet.augmentations.RegressionSMOTE at 0x129b70390>]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'random_state': None,\n",
       " 'refit': True,\n",
       " 'return_train_score': True,\n",
       " 'scoring': 'r2',\n",
       " 'verbose': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4381.92529|  0:00:00s\n",
      "epoch 1  | loss: 4477.31396|  0:00:00s\n",
      "epoch 2  | loss: 4332.4541|  0:00:00s\n",
      "epoch 3  | loss: 4335.12695|  0:00:00s\n",
      "epoch 4  | loss: 4434.16113|  0:00:00s\n",
      "epoch 5  | loss: 4293.05078|  0:00:00s\n",
      "epoch 6  | loss: 4295.91406|  0:00:00s\n",
      "epoch 7  | loss: 4278.11621|  0:00:00s\n",
      "epoch 8  | loss: 4191.25488|  0:00:00s\n",
      "epoch 9  | loss: 4115.03027|  0:00:00s\n",
      "epoch 10 | loss: 4070.47754|  0:00:00s\n",
      "epoch 11 | loss: 4045.5376|  0:00:00s\n",
      "epoch 12 | loss: 3953.68701|  0:00:00s\n",
      "epoch 13 | loss: 3957.26221|  0:00:00s\n",
      "epoch 14 | loss: 3819.87036|  0:00:00s\n",
      "epoch 15 | loss: 3798.51685|  0:00:00s\n",
      "epoch 16 | loss: 3733.75684|  0:00:00s\n",
      "epoch 17 | loss: 3757.92163|  0:00:00s\n",
      "epoch 18 | loss: 3634.28394|  0:00:00s\n",
      "epoch 19 | loss: 3530.59521|  0:00:00s\n",
      "epoch 20 | loss: 3434.26465|  0:00:00s\n",
      "epoch 21 | loss: 3369.76074|  0:00:00s\n",
      "epoch 22 | loss: 3295.0564|  0:00:00s\n",
      "epoch 23 | loss: 3116.08594|  0:00:00s\n",
      "epoch 24 | loss: 3115.02222|  0:00:00s\n",
      "epoch 25 | loss: 3031.24194|  0:00:00s\n",
      "epoch 26 | loss: 2838.21899|  0:00:00s\n",
      "epoch 27 | loss: 2822.99268|  0:00:01s\n",
      "epoch 28 | loss: 2678.71143|  0:00:01s\n",
      "epoch 29 | loss: 2586.52051|  0:00:01s\n",
      "epoch 30 | loss: 2505.29785|  0:00:01s\n",
      "epoch 31 | loss: 2409.03516|  0:00:01s\n",
      "epoch 32 | loss: 2302.44946|  0:00:01s\n",
      "epoch 33 | loss: 2234.01196|  0:00:01s\n",
      "epoch 34 | loss: 2138.15088|  0:00:01s\n",
      "epoch 35 | loss: 2054.95142|  0:00:01s\n",
      "epoch 36 | loss: 1947.69434|  0:00:01s\n",
      "epoch 37 | loss: 1749.66602|  0:00:01s\n",
      "epoch 38 | loss: 1760.52649|  0:00:01s\n",
      "epoch 39 | loss: 1600.01794|  0:00:01s\n",
      "epoch 40 | loss: 1548.65356|  0:00:01s\n",
      "epoch 41 | loss: 1480.06531|  0:00:01s\n",
      "epoch 42 | loss: 1365.79846|  0:00:01s\n",
      "epoch 43 | loss: 1333.87903|  0:00:01s\n",
      "epoch 44 | loss: 1231.21082|  0:00:01s\n",
      "epoch 45 | loss: 1150.36133|  0:00:01s\n",
      "epoch 46 | loss: 1087.73279|  0:00:01s\n",
      "epoch 47 | loss: 1007.54681|  0:00:01s\n",
      "epoch 48 | loss: 944.4469|  0:00:01s\n",
      "epoch 49 | loss: 890.88171|  0:00:01s\n",
      "{'eval_metric': 'rmse', 'max_epochs': 50, 'patience': 50, 'batch_size': 1024, 'num_workers': 0, 'drop_last': False, 'augmentations': <pytorch_tabnet.augmentations.RegressionSMOTE object at 0x129a81898>}\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 50\n",
    "\n",
    "aug = RegressionSMOTE(p=0.2)\n",
    "\n",
    "hyper_params = {\n",
    "    # 'eval_name':['train'],\n",
    "    'eval_metric':'rmse',\n",
    "    'max_epochs':max_epochs,\n",
    "    'patience':50,\n",
    "    'batch_size':1024,\n",
    "    # 'virtual_batch_size':[128],\n",
    "    'num_workers':0,\n",
    "    'drop_last':False,\n",
    "    'augmentations':aug,\n",
    "}\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "best_model = model_cv.fit(X=x_train_tf.numpy(), y=y_train_tf.numpy(), params=hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4381.92529|  0:00:00s\n",
      "epoch 1  | loss: 4477.31396|  0:00:00s\n",
      "epoch 2  | loss: 4332.4541|  0:00:00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3  | loss: 4335.12695|  0:00:00s\n",
      "epoch 4  | loss: 4434.16113|  0:00:00s\n",
      "epoch 5  | loss: 4293.05078|  0:00:00s\n",
      "epoch 6  | loss: 4295.91406|  0:00:00s\n",
      "epoch 7  | loss: 4278.11621|  0:00:00s\n",
      "epoch 8  | loss: 4191.25488|  0:00:00s\n",
      "epoch 9  | loss: 4115.03027|  0:00:00s\n",
      "epoch 10 | loss: 4070.47754|  0:00:00s\n",
      "epoch 11 | loss: 4045.5376|  0:00:00s\n",
      "epoch 12 | loss: 3953.68701|  0:00:00s\n",
      "epoch 13 | loss: 3957.26221|  0:00:00s\n",
      "epoch 14 | loss: 3819.87036|  0:00:00s\n",
      "epoch 15 | loss: 3798.51685|  0:00:00s\n",
      "epoch 16 | loss: 3733.75684|  0:00:00s\n",
      "epoch 17 | loss: 3757.92163|  0:00:00s\n",
      "epoch 18 | loss: 3634.28394|  0:00:00s\n",
      "epoch 19 | loss: 3530.59521|  0:00:00s\n",
      "epoch 20 | loss: 3434.26465|  0:00:00s\n",
      "epoch 21 | loss: 3369.76074|  0:00:00s\n",
      "epoch 22 | loss: 3295.0564|  0:00:00s\n",
      "epoch 23 | loss: 3116.08594|  0:00:00s\n",
      "epoch 24 | loss: 3115.02222|  0:00:00s\n",
      "epoch 25 | loss: 3031.24194|  0:00:00s\n",
      "epoch 26 | loss: 2838.21899|  0:00:00s\n",
      "epoch 27 | loss: 2822.99268|  0:00:01s\n",
      "epoch 28 | loss: 2678.71143|  0:00:01s\n",
      "epoch 29 | loss: 2586.52051|  0:00:01s\n",
      "epoch 30 | loss: 2505.29785|  0:00:01s\n",
      "epoch 31 | loss: 2409.03516|  0:00:01s\n",
      "epoch 32 | loss: 2302.44946|  0:00:01s\n",
      "epoch 33 | loss: 2234.01196|  0:00:01s\n",
      "epoch 34 | loss: 2138.15088|  0:00:01s\n",
      "epoch 35 | loss: 2054.95142|  0:00:01s\n",
      "epoch 36 | loss: 1947.69434|  0:00:01s\n",
      "epoch 37 | loss: 1749.66602|  0:00:01s\n",
      "epoch 38 | loss: 1760.52649|  0:00:01s\n",
      "epoch 39 | loss: 1600.01794|  0:00:01s\n",
      "epoch 40 | loss: 1548.65356|  0:00:01s\n",
      "epoch 41 | loss: 1480.06531|  0:00:01s\n",
      "epoch 42 | loss: 1365.79846|  0:00:01s\n",
      "epoch 43 | loss: 1333.87903|  0:00:01s\n",
      "epoch 44 | loss: 1231.21082|  0:00:01s\n",
      "epoch 45 | loss: 1150.36133|  0:00:01s\n",
      "epoch 46 | loss: 1087.73279|  0:00:01s\n",
      "epoch 47 | loss: 1007.54681|  0:00:01s\n",
      "epoch 48 | loss: 944.4469|  0:00:01s\n",
      "epoch 49 | loss: 890.88171|  0:00:01s\n"
     ]
    }
   ],
   "source": [
    "clf = TN()\n",
    "\n",
    "aug = RegressionSMOTE(p=0.2)\n",
    "\n",
    "clf.fit(X_train=x_train_tf.numpy(), y_train=y_train_tf.numpy(),\n",
    "    # eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    # eval_name=['train', 'valid'],\n",
    "    eval_metric=['rmsle', 'mae', 'rmse', 'mse'],\n",
    "    max_epochs=max_epochs,\n",
    "    patience=50,\n",
    "    batch_size=1024, virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    augmentations=aug, #aug\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4381.92529|  0:00:00s\n",
      "epoch 1  | loss: 4477.31396|  0:00:00s\n",
      "epoch 2  | loss: 4332.4541|  0:00:00s\n",
      "epoch 3  | loss: 4335.12695|  0:00:00s\n",
      "epoch 4  | loss: 4434.16113|  0:00:00s\n",
      "epoch 5  | loss: 4293.05078|  0:00:00s\n",
      "epoch 6  | loss: 4295.91406|  0:00:00s\n",
      "epoch 7  | loss: 4278.11621|  0:00:00s\n",
      "epoch 8  | loss: 4191.25488|  0:00:00s\n",
      "epoch 9  | loss: 4115.03027|  0:00:00s\n",
      "epoch 10 | loss: 4070.47754|  0:00:00s\n",
      "epoch 11 | loss: 4045.5376|  0:00:00s\n",
      "epoch 12 | loss: 3953.68701|  0:00:00s\n",
      "epoch 13 | loss: 3957.26221|  0:00:00s\n",
      "epoch 14 | loss: 3819.87036|  0:00:00s\n",
      "epoch 15 | loss: 3798.51685|  0:00:00s\n",
      "epoch 16 | loss: 3733.75684|  0:00:00s\n",
      "epoch 17 | loss: 3757.92163|  0:00:00s\n",
      "epoch 18 | loss: 3634.28394|  0:00:00s\n",
      "epoch 19 | loss: 3530.59521|  0:00:00s\n",
      "epoch 20 | loss: 3434.26465|  0:00:00s\n",
      "epoch 21 | loss: 3369.76074|  0:00:00s\n",
      "epoch 22 | loss: 3295.0564|  0:00:00s\n",
      "epoch 23 | loss: 3116.08594|  0:00:01s\n",
      "epoch 24 | loss: 3115.02222|  0:00:01s\n",
      "epoch 25 | loss: 3031.24194|  0:00:01s\n",
      "epoch 26 | loss: 2838.21899|  0:00:01s\n",
      "epoch 27 | loss: 2822.99268|  0:00:01s\n",
      "epoch 28 | loss: 2678.71143|  0:00:01s\n",
      "epoch 29 | loss: 2586.52051|  0:00:01s\n",
      "epoch 30 | loss: 2505.29785|  0:00:01s\n",
      "epoch 31 | loss: 2409.03516|  0:00:01s\n",
      "epoch 32 | loss: 2302.44946|  0:00:01s\n",
      "epoch 33 | loss: 2234.01196|  0:00:01s\n",
      "epoch 34 | loss: 2138.15088|  0:00:01s\n",
      "epoch 35 | loss: 2054.95142|  0:00:01s\n",
      "epoch 36 | loss: 1947.69434|  0:00:01s\n",
      "epoch 37 | loss: 1749.66602|  0:00:01s\n",
      "epoch 38 | loss: 1760.52649|  0:00:01s\n",
      "epoch 39 | loss: 1600.01794|  0:00:01s\n",
      "epoch 40 | loss: 1548.65356|  0:00:01s\n",
      "epoch 41 | loss: 1480.06531|  0:00:01s\n",
      "epoch 42 | loss: 1365.79846|  0:00:01s\n",
      "epoch 43 | loss: 1333.87903|  0:00:01s\n",
      "epoch 44 | loss: 1231.21082|  0:00:01s\n",
      "epoch 45 | loss: 1150.36133|  0:00:02s\n",
      "epoch 46 | loss: 1087.73279|  0:00:02s\n",
      "epoch 47 | loss: 1007.54681|  0:00:02s\n",
      "epoch 48 | loss: 944.4469|  0:00:02s\n",
      "epoch 49 | loss: 890.88171|  0:00:02s\n",
      "{'augmentations': <pytorch_tabnet.augmentations.RegressionSMOTE object at 0x12c1496a0>, 'batch_size': 1024, 'drop_last': False, 'eval_metric': 'rmse', 'max_epochs': 50, 'num_workers': 0, 'patience': 50, 'virtual_batch_size': 128}\n",
      "[[60.23117 ]\n",
      " [54.39115 ]\n",
      " [63.43062 ]\n",
      " [59.334133]\n",
      " [61.88777 ]\n",
      " [65.74707 ]\n",
      " [42.745224]\n",
      " [62.79294 ]\n",
      " [56.76098 ]\n",
      " [36.524616]\n",
      " [62.62951 ]\n",
      " [44.430782]\n",
      " [72.26399 ]\n",
      " [61.281578]\n",
      " [72.50192 ]\n",
      " [45.298374]\n",
      " [74.25104 ]\n",
      " [43.960014]\n",
      " [69.55649 ]\n",
      " [41.976913]\n",
      " [61.730988]\n",
      " [55.186615]\n",
      " [68.0451  ]\n",
      " [66.61631 ]\n",
      " [49.067535]\n",
      " [64.574135]\n",
      " [42.630863]\n",
      " [62.87755 ]\n",
      " [73.68086 ]\n",
      " [57.814617]\n",
      " [62.49225 ]\n",
      " [61.431683]\n",
      " [60.23233 ]\n",
      " [38.273087]\n",
      " [41.26091 ]\n",
      " [49.36937 ]\n",
      " [65.25845 ]\n",
      " [73.62394 ]\n",
      " [65.260414]\n",
      " [72.49123 ]\n",
      " [45.604733]\n",
      " [67.07146 ]\n",
      " [68.415535]\n",
      " [42.206444]\n",
      " [40.97438 ]\n",
      " [64.9309  ]\n",
      " [73.28914 ]\n",
      " [68.87916 ]\n",
      " [62.074036]\n",
      " [54.021873]\n",
      " [39.495018]\n",
      " [63.926907]\n",
      " [55.235878]\n",
      " [46.41667 ]\n",
      " [63.97428 ]\n",
      " [61.892952]\n",
      " [60.015575]\n",
      " [62.8506  ]\n",
      " [62.257042]\n",
      " [65.94771 ]\n",
      " [55.841896]\n",
      " [51.70161 ]\n",
      " [62.335552]\n",
      " [72.639465]\n",
      " [61.421883]\n",
      " [45.49151 ]\n",
      " [57.70807 ]\n",
      " [64.39366 ]\n",
      " [49.96189 ]\n",
      " [52.943813]\n",
      " [65.99477 ]\n",
      " [45.053802]\n",
      " [63.26612 ]\n",
      " [64.35472 ]\n",
      " [64.39198 ]\n",
      " [61.61534 ]\n",
      " [39.393383]\n",
      " [65.31154 ]\n",
      " [70.25133 ]\n",
      " [48.057068]\n",
      " [57.51619 ]]\n",
      "epoch 0  | loss: 4381.92529|  0:00:00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1  | loss: 4477.31396|  0:00:00s\n",
      "epoch 2  | loss: 4332.4541|  0:00:00s\n",
      "epoch 3  | loss: 4335.12695|  0:00:00s\n",
      "epoch 4  | loss: 4434.16113|  0:00:00s\n",
      "epoch 5  | loss: 4293.05078|  0:00:00s\n",
      "epoch 6  | loss: 4295.91406|  0:00:00s\n",
      "epoch 7  | loss: 4278.11621|  0:00:00s\n",
      "epoch 8  | loss: 4191.25488|  0:00:00s\n",
      "epoch 9  | loss: 4115.03027|  0:00:00s\n",
      "epoch 10 | loss: 4070.47754|  0:00:00s\n",
      "epoch 11 | loss: 4045.5376|  0:00:00s\n",
      "epoch 12 | loss: 3953.68701|  0:00:00s\n",
      "epoch 13 | loss: 3957.26221|  0:00:00s\n",
      "epoch 14 | loss: 3819.87036|  0:00:00s\n",
      "epoch 15 | loss: 3798.51685|  0:00:00s\n",
      "epoch 16 | loss: 3733.75684|  0:00:00s\n",
      "epoch 17 | loss: 3757.92163|  0:00:00s\n",
      "epoch 18 | loss: 3634.28394|  0:00:00s\n",
      "epoch 19 | loss: 3530.59521|  0:00:01s\n",
      "epoch 20 | loss: 3434.26465|  0:00:01s\n",
      "epoch 21 | loss: 3369.76074|  0:00:01s\n",
      "epoch 22 | loss: 3295.0564|  0:00:01s\n",
      "epoch 23 | loss: 3116.08594|  0:00:01s\n",
      "epoch 24 | loss: 3115.02222|  0:00:01s\n",
      "epoch 25 | loss: 3031.24194|  0:00:01s\n",
      "epoch 26 | loss: 2838.21899|  0:00:01s\n",
      "epoch 27 | loss: 2822.99268|  0:00:01s\n",
      "epoch 28 | loss: 2678.71143|  0:00:01s\n",
      "epoch 29 | loss: 2586.52051|  0:00:01s\n",
      "epoch 30 | loss: 2505.29785|  0:00:01s\n",
      "epoch 31 | loss: 2409.03516|  0:00:01s\n",
      "epoch 32 | loss: 2302.44946|  0:00:01s\n",
      "epoch 33 | loss: 2234.01196|  0:00:01s\n",
      "epoch 34 | loss: 2138.15088|  0:00:01s\n",
      "epoch 35 | loss: 2054.95142|  0:00:01s\n",
      "epoch 36 | loss: 1947.69434|  0:00:01s\n",
      "epoch 37 | loss: 1749.66602|  0:00:01s\n",
      "epoch 38 | loss: 1760.52649|  0:00:01s\n",
      "epoch 39 | loss: 1600.01794|  0:00:01s\n",
      "epoch 40 | loss: 1548.65356|  0:00:01s\n",
      "epoch 41 | loss: 1480.06531|  0:00:01s\n",
      "epoch 42 | loss: 1365.79846|  0:00:02s\n",
      "epoch 43 | loss: 1333.87903|  0:00:02s\n",
      "epoch 44 | loss: 1231.21082|  0:00:02s\n",
      "epoch 45 | loss: 1150.36133|  0:00:02s\n",
      "epoch 46 | loss: 1087.73279|  0:00:02s\n",
      "epoch 47 | loss: 1007.54681|  0:00:02s\n",
      "epoch 48 | loss: 944.4469|  0:00:02s\n",
      "epoch 49 | loss: 890.88171|  0:00:02s\n",
      "{'augmentations': <pytorch_tabnet.augmentations.RegressionSMOTE object at 0x12c1496a0>, 'batch_size': 1024, 'drop_last': False, 'eval_metric': 'rmse', 'max_epochs': 50, 'num_workers': 0, 'patience': 100, 'virtual_batch_size': 128}\n",
      "[[60.23117 ]\n",
      " [54.39115 ]\n",
      " [63.43062 ]\n",
      " [59.334133]\n",
      " [61.88777 ]\n",
      " [65.74707 ]\n",
      " [42.745224]\n",
      " [62.79294 ]\n",
      " [56.76098 ]\n",
      " [36.524616]\n",
      " [62.62951 ]\n",
      " [44.430782]\n",
      " [72.26399 ]\n",
      " [61.281578]\n",
      " [72.50192 ]\n",
      " [45.298374]\n",
      " [74.25104 ]\n",
      " [43.960014]\n",
      " [69.55649 ]\n",
      " [41.976913]\n",
      " [61.730988]\n",
      " [55.186615]\n",
      " [68.0451  ]\n",
      " [66.61631 ]\n",
      " [49.067535]\n",
      " [64.574135]\n",
      " [42.630863]\n",
      " [62.87755 ]\n",
      " [73.68086 ]\n",
      " [57.814617]\n",
      " [62.49225 ]\n",
      " [61.431683]\n",
      " [60.23233 ]\n",
      " [38.273087]\n",
      " [41.26091 ]\n",
      " [49.36937 ]\n",
      " [65.25845 ]\n",
      " [73.62394 ]\n",
      " [65.260414]\n",
      " [72.49123 ]\n",
      " [45.604733]\n",
      " [67.07146 ]\n",
      " [68.415535]\n",
      " [42.206444]\n",
      " [40.97438 ]\n",
      " [64.9309  ]\n",
      " [73.28914 ]\n",
      " [68.87916 ]\n",
      " [62.074036]\n",
      " [54.021873]\n",
      " [39.495018]\n",
      " [63.926907]\n",
      " [55.235878]\n",
      " [46.41667 ]\n",
      " [63.97428 ]\n",
      " [61.892952]\n",
      " [60.015575]\n",
      " [62.8506  ]\n",
      " [62.257042]\n",
      " [65.94771 ]\n",
      " [55.841896]\n",
      " [51.70161 ]\n",
      " [62.335552]\n",
      " [72.639465]\n",
      " [61.421883]\n",
      " [45.49151 ]\n",
      " [57.70807 ]\n",
      " [64.39366 ]\n",
      " [49.96189 ]\n",
      " [52.943813]\n",
      " [65.99477 ]\n",
      " [45.053802]\n",
      " [63.26612 ]\n",
      " [64.35472 ]\n",
      " [64.39198 ]\n",
      " [61.61534 ]\n",
      " [39.393383]\n",
      " [65.31154 ]\n",
      " [70.25133 ]\n",
      " [48.057068]\n",
      " [57.51619 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4381.92529|  0:00:00s\n",
      "epoch 1  | loss: 4477.31396|  0:00:00s\n",
      "epoch 2  | loss: 4332.4541|  0:00:00s\n",
      "epoch 3  | loss: 4335.12695|  0:00:00s\n",
      "epoch 4  | loss: 4434.16113|  0:00:00s\n",
      "epoch 5  | loss: 4293.05078|  0:00:00s\n",
      "epoch 6  | loss: 4295.91406|  0:00:00s\n",
      "epoch 7  | loss: 4278.11621|  0:00:00s\n",
      "epoch 8  | loss: 4191.25488|  0:00:00s\n",
      "epoch 9  | loss: 4115.03027|  0:00:00s\n",
      "epoch 10 | loss: 4070.47754|  0:00:00s\n",
      "epoch 11 | loss: 4045.5376|  0:00:00s\n",
      "epoch 12 | loss: 3953.68701|  0:00:00s\n",
      "epoch 13 | loss: 3957.26221|  0:00:00s\n",
      "epoch 14 | loss: 3819.87036|  0:00:00s\n",
      "epoch 15 | loss: 3798.51685|  0:00:00s\n",
      "epoch 16 | loss: 3733.75684|  0:00:00s\n",
      "epoch 17 | loss: 3757.92163|  0:00:00s\n",
      "epoch 18 | loss: 3634.28394|  0:00:00s\n",
      "epoch 19 | loss: 3530.59521|  0:00:00s\n",
      "epoch 20 | loss: 3434.26465|  0:00:00s\n",
      "epoch 21 | loss: 3369.76074|  0:00:00s\n",
      "epoch 22 | loss: 3295.0564|  0:00:01s\n",
      "epoch 23 | loss: 3116.08594|  0:00:01s\n",
      "epoch 24 | loss: 3115.02222|  0:00:01s\n",
      "epoch 25 | loss: 3031.24194|  0:00:01s\n",
      "epoch 26 | loss: 2838.21899|  0:00:01s\n",
      "epoch 27 | loss: 2822.99268|  0:00:01s\n",
      "epoch 28 | loss: 2678.71143|  0:00:01s\n",
      "epoch 29 | loss: 2586.52051|  0:00:01s\n",
      "epoch 30 | loss: 2505.29785|  0:00:01s\n",
      "epoch 31 | loss: 2409.03516|  0:00:01s\n",
      "epoch 32 | loss: 2302.44946|  0:00:01s\n",
      "epoch 33 | loss: 2234.01196|  0:00:01s\n",
      "epoch 34 | loss: 2138.15088|  0:00:01s\n",
      "epoch 35 | loss: 2054.95142|  0:00:01s\n",
      "epoch 36 | loss: 1947.69434|  0:00:01s\n",
      "epoch 37 | loss: 1749.66602|  0:00:01s\n",
      "epoch 38 | loss: 1760.52649|  0:00:01s\n",
      "epoch 39 | loss: 1600.01794|  0:00:01s\n",
      "epoch 40 | loss: 1548.65356|  0:00:01s\n",
      "epoch 41 | loss: 1480.06531|  0:00:01s\n",
      "epoch 42 | loss: 1365.79846|  0:00:01s\n",
      "epoch 43 | loss: 1333.87903|  0:00:01s\n",
      "epoch 44 | loss: 1231.21082|  0:00:01s\n",
      "epoch 45 | loss: 1150.36133|  0:00:01s\n",
      "epoch 46 | loss: 1087.73279|  0:00:01s\n",
      "epoch 47 | loss: 1007.54681|  0:00:01s\n",
      "epoch 48 | loss: 944.4469|  0:00:02s\n",
      "epoch 49 | loss: 890.88171|  0:00:02s\n",
      "{'augmentations': <pytorch_tabnet.augmentations.RegressionSMOTE object at 0x12c1496a0>, 'batch_size': 1024, 'drop_last': False, 'eval_metric': 'rmse', 'max_epochs': 50, 'num_workers': 0, 'patience': 150, 'virtual_batch_size': 128}\n",
      "[[60.23117 ]\n",
      " [54.39115 ]\n",
      " [63.43062 ]\n",
      " [59.334133]\n",
      " [61.88777 ]\n",
      " [65.74707 ]\n",
      " [42.745224]\n",
      " [62.79294 ]\n",
      " [56.76098 ]\n",
      " [36.524616]\n",
      " [62.62951 ]\n",
      " [44.430782]\n",
      " [72.26399 ]\n",
      " [61.281578]\n",
      " [72.50192 ]\n",
      " [45.298374]\n",
      " [74.25104 ]\n",
      " [43.960014]\n",
      " [69.55649 ]\n",
      " [41.976913]\n",
      " [61.730988]\n",
      " [55.186615]\n",
      " [68.0451  ]\n",
      " [66.61631 ]\n",
      " [49.067535]\n",
      " [64.574135]\n",
      " [42.630863]\n",
      " [62.87755 ]\n",
      " [73.68086 ]\n",
      " [57.814617]\n",
      " [62.49225 ]\n",
      " [61.431683]\n",
      " [60.23233 ]\n",
      " [38.273087]\n",
      " [41.26091 ]\n",
      " [49.36937 ]\n",
      " [65.25845 ]\n",
      " [73.62394 ]\n",
      " [65.260414]\n",
      " [72.49123 ]\n",
      " [45.604733]\n",
      " [67.07146 ]\n",
      " [68.415535]\n",
      " [42.206444]\n",
      " [40.97438 ]\n",
      " [64.9309  ]\n",
      " [73.28914 ]\n",
      " [68.87916 ]\n",
      " [62.074036]\n",
      " [54.021873]\n",
      " [39.495018]\n",
      " [63.926907]\n",
      " [55.235878]\n",
      " [46.41667 ]\n",
      " [63.97428 ]\n",
      " [61.892952]\n",
      " [60.015575]\n",
      " [62.8506  ]\n",
      " [62.257042]\n",
      " [65.94771 ]\n",
      " [55.841896]\n",
      " [51.70161 ]\n",
      " [62.335552]\n",
      " [72.639465]\n",
      " [61.421883]\n",
      " [45.49151 ]\n",
      " [57.70807 ]\n",
      " [64.39366 ]\n",
      " [49.96189 ]\n",
      " [52.943813]\n",
      " [65.99477 ]\n",
      " [45.053802]\n",
      " [63.26612 ]\n",
      " [64.35472 ]\n",
      " [64.39198 ]\n",
      " [61.61534 ]\n",
      " [39.393383]\n",
      " [65.31154 ]\n",
      " [70.25133 ]\n",
      " [48.057068]\n",
      " [57.51619 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4381.92529|  0:00:01s\n",
      "epoch 1  | loss: 4477.31396|  0:00:01s\n",
      "epoch 2  | loss: 4332.4541|  0:00:01s\n",
      "epoch 3  | loss: 4335.12695|  0:00:01s\n",
      "epoch 4  | loss: 4434.16113|  0:00:01s\n",
      "epoch 5  | loss: 4293.05078|  0:00:01s\n",
      "epoch 6  | loss: 4295.91406|  0:00:01s\n",
      "epoch 7  | loss: 4278.11621|  0:00:02s\n",
      "epoch 8  | loss: 4191.25488|  0:00:02s\n",
      "epoch 9  | loss: 4115.03027|  0:00:02s\n",
      "epoch 10 | loss: 4070.47754|  0:00:02s\n",
      "epoch 11 | loss: 4045.5376|  0:00:02s\n",
      "epoch 12 | loss: 3953.68701|  0:00:02s\n",
      "epoch 13 | loss: 3957.26221|  0:00:03s\n",
      "epoch 14 | loss: 3819.87036|  0:00:03s\n",
      "epoch 15 | loss: 3798.51685|  0:00:03s\n",
      "epoch 16 | loss: 3733.75684|  0:00:03s\n",
      "epoch 17 | loss: 3757.92163|  0:00:03s\n",
      "epoch 18 | loss: 3634.28394|  0:00:03s\n",
      "epoch 19 | loss: 3530.59521|  0:00:03s\n",
      "epoch 20 | loss: 3434.26465|  0:00:03s\n",
      "epoch 21 | loss: 3369.76074|  0:00:04s\n",
      "epoch 22 | loss: 3295.0564|  0:00:04s\n",
      "epoch 23 | loss: 3116.08594|  0:00:04s\n",
      "epoch 24 | loss: 3115.02222|  0:00:04s\n",
      "epoch 25 | loss: 3031.24194|  0:00:04s\n",
      "epoch 26 | loss: 2838.21899|  0:00:04s\n",
      "epoch 27 | loss: 2822.99268|  0:00:04s\n",
      "epoch 28 | loss: 2678.71143|  0:00:05s\n",
      "epoch 29 | loss: 2586.52051|  0:00:05s\n",
      "epoch 30 | loss: 2505.29785|  0:00:05s\n",
      "epoch 31 | loss: 2409.03516|  0:00:05s\n",
      "epoch 32 | loss: 2302.44946|  0:00:05s\n",
      "epoch 33 | loss: 2234.01196|  0:00:05s\n",
      "epoch 34 | loss: 2138.15088|  0:00:05s\n",
      "epoch 35 | loss: 2054.95142|  0:00:05s\n",
      "epoch 36 | loss: 1947.69434|  0:00:05s\n",
      "epoch 37 | loss: 1749.66602|  0:00:06s\n",
      "epoch 38 | loss: 1760.52649|  0:00:06s\n",
      "epoch 39 | loss: 1600.01794|  0:00:06s\n",
      "epoch 40 | loss: 1548.65356|  0:00:06s\n",
      "epoch 41 | loss: 1480.06531|  0:00:06s\n",
      "epoch 42 | loss: 1365.79846|  0:00:06s\n",
      "epoch 43 | loss: 1333.87903|  0:00:06s\n",
      "epoch 44 | loss: 1231.21082|  0:00:06s\n",
      "epoch 45 | loss: 1150.36133|  0:00:06s\n",
      "epoch 46 | loss: 1087.73279|  0:00:07s\n",
      "epoch 47 | loss: 1007.54681|  0:00:07s\n",
      "epoch 48 | loss: 944.4469|  0:00:07s\n",
      "epoch 49 | loss: 890.88171|  0:00:07s\n",
      "{'augmentations': <pytorch_tabnet.augmentations.RegressionSMOTE object at 0x12c1496a0>, 'batch_size': 1024, 'drop_last': False, 'eval_metric': 'rmse', 'max_epochs': 50, 'num_workers': 1, 'patience': 50, 'virtual_batch_size': 128}\n",
      "[[60.23117 ]\n",
      " [54.39115 ]\n",
      " [63.43062 ]\n",
      " [59.334133]\n",
      " [61.88777 ]\n",
      " [65.74707 ]\n",
      " [42.745224]\n",
      " [62.79294 ]\n",
      " [56.76098 ]\n",
      " [36.524616]\n",
      " [62.62951 ]\n",
      " [44.430782]\n",
      " [72.26399 ]\n",
      " [61.281578]\n",
      " [72.50192 ]\n",
      " [45.298374]\n",
      " [74.25104 ]\n",
      " [43.960014]\n",
      " [69.55649 ]\n",
      " [41.976913]\n",
      " [61.730988]\n",
      " [55.186615]\n",
      " [68.0451  ]\n",
      " [66.61631 ]\n",
      " [49.067535]\n",
      " [64.574135]\n",
      " [42.630863]\n",
      " [62.87755 ]\n",
      " [73.68086 ]\n",
      " [57.814617]\n",
      " [62.49225 ]\n",
      " [61.431683]\n",
      " [60.23233 ]\n",
      " [38.273087]\n",
      " [41.26091 ]\n",
      " [49.36937 ]\n",
      " [65.25845 ]\n",
      " [73.62394 ]\n",
      " [65.260414]\n",
      " [72.49123 ]\n",
      " [45.604733]\n",
      " [67.07146 ]\n",
      " [68.415535]\n",
      " [42.206444]\n",
      " [40.97438 ]\n",
      " [64.9309  ]\n",
      " [73.28914 ]\n",
      " [68.87916 ]\n",
      " [62.074036]\n",
      " [54.021873]\n",
      " [39.495018]\n",
      " [63.926907]\n",
      " [55.235878]\n",
      " [46.41667 ]\n",
      " [63.97428 ]\n",
      " [61.892952]\n",
      " [60.015575]\n",
      " [62.8506  ]\n",
      " [62.257042]\n",
      " [65.94771 ]\n",
      " [55.841896]\n",
      " [51.70161 ]\n",
      " [62.335552]\n",
      " [72.639465]\n",
      " [61.421883]\n",
      " [45.49151 ]\n",
      " [57.70807 ]\n",
      " [64.39366 ]\n",
      " [49.96189 ]\n",
      " [52.943813]\n",
      " [65.99477 ]\n",
      " [45.053802]\n",
      " [63.26612 ]\n",
      " [64.35472 ]\n",
      " [64.39198 ]\n",
      " [61.61534 ]\n",
      " [39.393383]\n",
      " [65.31154 ]\n",
      " [70.25133 ]\n",
      " [48.057068]\n",
      " [57.51619 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4381.92529|  0:00:00s\n",
      "epoch 1  | loss: 4477.31396|  0:00:00s\n",
      "epoch 2  | loss: 4332.4541|  0:00:00s\n",
      "epoch 3  | loss: 4335.12695|  0:00:00s\n",
      "epoch 4  | loss: 4434.16113|  0:00:00s\n",
      "epoch 5  | loss: 4293.05078|  0:00:00s\n",
      "epoch 6  | loss: 4295.91406|  0:00:00s\n",
      "epoch 7  | loss: 4278.11621|  0:00:01s\n",
      "epoch 8  | loss: 4191.25488|  0:00:01s\n",
      "epoch 9  | loss: 4115.03027|  0:00:01s\n",
      "epoch 10 | loss: 4070.47754|  0:00:01s\n",
      "epoch 11 | loss: 4045.5376|  0:00:01s\n",
      "epoch 12 | loss: 3953.68701|  0:00:01s\n",
      "epoch 13 | loss: 3957.26221|  0:00:01s\n",
      "epoch 14 | loss: 3819.87036|  0:00:02s\n",
      "epoch 15 | loss: 3798.51685|  0:00:02s\n",
      "epoch 16 | loss: 3733.75684|  0:00:02s\n",
      "epoch 17 | loss: 3757.92163|  0:00:02s\n",
      "epoch 18 | loss: 3634.28394|  0:00:02s\n",
      "epoch 19 | loss: 3530.59521|  0:00:02s\n",
      "epoch 20 | loss: 3434.26465|  0:00:02s\n",
      "epoch 21 | loss: 3369.76074|  0:00:03s\n",
      "epoch 22 | loss: 3295.0564|  0:00:03s\n",
      "epoch 23 | loss: 3116.08594|  0:00:03s\n",
      "epoch 24 | loss: 3115.02222|  0:00:03s\n",
      "epoch 25 | loss: 3031.24194|  0:00:03s\n",
      "epoch 26 | loss: 2838.21899|  0:00:03s\n",
      "epoch 27 | loss: 2822.99268|  0:00:03s\n",
      "epoch 28 | loss: 2678.71143|  0:00:03s\n",
      "epoch 29 | loss: 2586.52051|  0:00:04s\n",
      "epoch 30 | loss: 2505.29785|  0:00:04s\n",
      "epoch 31 | loss: 2409.03516|  0:00:04s\n",
      "epoch 32 | loss: 2302.44946|  0:00:04s\n",
      "epoch 33 | loss: 2234.01196|  0:00:04s\n",
      "epoch 34 | loss: 2138.15088|  0:00:04s\n",
      "epoch 35 | loss: 2054.95142|  0:00:04s\n",
      "epoch 36 | loss: 1947.69434|  0:00:04s\n",
      "epoch 37 | loss: 1749.66602|  0:00:04s\n",
      "epoch 38 | loss: 1760.52649|  0:00:05s\n",
      "epoch 39 | loss: 1600.01794|  0:00:05s\n",
      "epoch 40 | loss: 1548.65356|  0:00:05s\n",
      "epoch 41 | loss: 1480.06531|  0:00:05s\n",
      "epoch 42 | loss: 1365.79846|  0:00:05s\n",
      "epoch 43 | loss: 1333.87903|  0:00:05s\n",
      "epoch 44 | loss: 1231.21082|  0:00:05s\n",
      "epoch 45 | loss: 1150.36133|  0:00:05s\n",
      "epoch 46 | loss: 1087.73279|  0:00:05s\n",
      "epoch 47 | loss: 1007.54681|  0:00:06s\n",
      "epoch 48 | loss: 944.4469|  0:00:06s\n",
      "epoch 49 | loss: 890.88171|  0:00:06s\n",
      "{'augmentations': <pytorch_tabnet.augmentations.RegressionSMOTE object at 0x12c1496a0>, 'batch_size': 1024, 'drop_last': False, 'eval_metric': 'rmse', 'max_epochs': 50, 'num_workers': 1, 'patience': 100, 'virtual_batch_size': 128}\n",
      "[[60.23117 ]\n",
      " [54.39115 ]\n",
      " [63.43062 ]\n",
      " [59.334133]\n",
      " [61.88777 ]\n",
      " [65.74707 ]\n",
      " [42.745224]\n",
      " [62.79294 ]\n",
      " [56.76098 ]\n",
      " [36.524616]\n",
      " [62.62951 ]\n",
      " [44.430782]\n",
      " [72.26399 ]\n",
      " [61.281578]\n",
      " [72.50192 ]\n",
      " [45.298374]\n",
      " [74.25104 ]\n",
      " [43.960014]\n",
      " [69.55649 ]\n",
      " [41.976913]\n",
      " [61.730988]\n",
      " [55.186615]\n",
      " [68.0451  ]\n",
      " [66.61631 ]\n",
      " [49.067535]\n",
      " [64.574135]\n",
      " [42.630863]\n",
      " [62.87755 ]\n",
      " [73.68086 ]\n",
      " [57.814617]\n",
      " [62.49225 ]\n",
      " [61.431683]\n",
      " [60.23233 ]\n",
      " [38.273087]\n",
      " [41.26091 ]\n",
      " [49.36937 ]\n",
      " [65.25845 ]\n",
      " [73.62394 ]\n",
      " [65.260414]\n",
      " [72.49123 ]\n",
      " [45.604733]\n",
      " [67.07146 ]\n",
      " [68.415535]\n",
      " [42.206444]\n",
      " [40.97438 ]\n",
      " [64.9309  ]\n",
      " [73.28914 ]\n",
      " [68.87916 ]\n",
      " [62.074036]\n",
      " [54.021873]\n",
      " [39.495018]\n",
      " [63.926907]\n",
      " [55.235878]\n",
      " [46.41667 ]\n",
      " [63.97428 ]\n",
      " [61.892952]\n",
      " [60.015575]\n",
      " [62.8506  ]\n",
      " [62.257042]\n",
      " [65.94771 ]\n",
      " [55.841896]\n",
      " [51.70161 ]\n",
      " [62.335552]\n",
      " [72.639465]\n",
      " [61.421883]\n",
      " [45.49151 ]\n",
      " [57.70807 ]\n",
      " [64.39366 ]\n",
      " [49.96189 ]\n",
      " [52.943813]\n",
      " [65.99477 ]\n",
      " [45.053802]\n",
      " [63.26612 ]\n",
      " [64.35472 ]\n",
      " [64.39198 ]\n",
      " [61.61534 ]\n",
      " [39.393383]\n",
      " [65.31154 ]\n",
      " [70.25133 ]\n",
      " [48.057068]\n",
      " [57.51619 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4381.92529|  0:00:00s\n",
      "epoch 1  | loss: 4477.31396|  0:00:00s\n",
      "epoch 2  | loss: 4332.4541|  0:00:00s\n",
      "epoch 3  | loss: 4335.12695|  0:00:00s\n",
      "epoch 4  | loss: 4434.16113|  0:00:00s\n",
      "epoch 5  | loss: 4293.05078|  0:00:00s\n",
      "epoch 6  | loss: 4295.91406|  0:00:00s\n",
      "epoch 7  | loss: 4278.11621|  0:00:00s\n",
      "epoch 8  | loss: 4191.25488|  0:00:01s\n",
      "epoch 9  | loss: 4115.03027|  0:00:01s\n",
      "epoch 10 | loss: 4070.47754|  0:00:01s\n",
      "epoch 11 | loss: 4045.5376|  0:00:01s\n",
      "epoch 12 | loss: 3953.68701|  0:00:01s\n",
      "epoch 13 | loss: 3957.26221|  0:00:01s\n",
      "epoch 14 | loss: 3819.87036|  0:00:01s\n",
      "epoch 15 | loss: 3798.51685|  0:00:01s\n",
      "epoch 16 | loss: 3733.75684|  0:00:02s\n",
      "epoch 17 | loss: 3757.92163|  0:00:02s\n",
      "epoch 18 | loss: 3634.28394|  0:00:02s\n",
      "epoch 19 | loss: 3530.59521|  0:00:02s\n",
      "epoch 20 | loss: 3434.26465|  0:00:02s\n",
      "epoch 21 | loss: 3369.76074|  0:00:02s\n",
      "epoch 22 | loss: 3295.0564|  0:00:02s\n",
      "epoch 23 | loss: 3116.08594|  0:00:02s\n",
      "epoch 24 | loss: 3115.02222|  0:00:02s\n",
      "epoch 25 | loss: 3031.24194|  0:00:03s\n",
      "epoch 26 | loss: 2838.21899|  0:00:03s\n",
      "epoch 27 | loss: 2822.99268|  0:00:03s\n",
      "epoch 28 | loss: 2678.71143|  0:00:03s\n",
      "epoch 29 | loss: 2586.52051|  0:00:03s\n",
      "epoch 30 | loss: 2505.29785|  0:00:03s\n",
      "epoch 31 | loss: 2409.03516|  0:00:03s\n",
      "epoch 32 | loss: 2302.44946|  0:00:03s\n",
      "epoch 33 | loss: 2234.01196|  0:00:04s\n",
      "epoch 34 | loss: 2138.15088|  0:00:04s\n",
      "epoch 35 | loss: 2054.95142|  0:00:04s\n",
      "epoch 36 | loss: 1947.69434|  0:00:04s\n",
      "epoch 37 | loss: 1749.66602|  0:00:04s\n",
      "epoch 38 | loss: 1760.52649|  0:00:04s\n",
      "epoch 39 | loss: 1600.01794|  0:00:04s\n",
      "epoch 40 | loss: 1548.65356|  0:00:04s\n",
      "epoch 41 | loss: 1480.06531|  0:00:04s\n",
      "epoch 42 | loss: 1365.79846|  0:00:05s\n",
      "epoch 43 | loss: 1333.87903|  0:00:05s\n",
      "epoch 44 | loss: 1231.21082|  0:00:05s\n",
      "epoch 45 | loss: 1150.36133|  0:00:05s\n",
      "epoch 46 | loss: 1087.73279|  0:00:05s\n",
      "epoch 47 | loss: 1007.54681|  0:00:05s\n",
      "epoch 48 | loss: 944.4469|  0:00:05s\n",
      "epoch 49 | loss: 890.88171|  0:00:05s\n",
      "{'augmentations': <pytorch_tabnet.augmentations.RegressionSMOTE object at 0x12c1496a0>, 'batch_size': 1024, 'drop_last': False, 'eval_metric': 'rmse', 'max_epochs': 50, 'num_workers': 1, 'patience': 150, 'virtual_batch_size': 128}\n",
      "[[60.23117 ]\n",
      " [54.39115 ]\n",
      " [63.43062 ]\n",
      " [59.334133]\n",
      " [61.88777 ]\n",
      " [65.74707 ]\n",
      " [42.745224]\n",
      " [62.79294 ]\n",
      " [56.76098 ]\n",
      " [36.524616]\n",
      " [62.62951 ]\n",
      " [44.430782]\n",
      " [72.26399 ]\n",
      " [61.281578]\n",
      " [72.50192 ]\n",
      " [45.298374]\n",
      " [74.25104 ]\n",
      " [43.960014]\n",
      " [69.55649 ]\n",
      " [41.976913]\n",
      " [61.730988]\n",
      " [55.186615]\n",
      " [68.0451  ]\n",
      " [66.61631 ]\n",
      " [49.067535]\n",
      " [64.574135]\n",
      " [42.630863]\n",
      " [62.87755 ]\n",
      " [73.68086 ]\n",
      " [57.814617]\n",
      " [62.49225 ]\n",
      " [61.431683]\n",
      " [60.23233 ]\n",
      " [38.273087]\n",
      " [41.26091 ]\n",
      " [49.36937 ]\n",
      " [65.25845 ]\n",
      " [73.62394 ]\n",
      " [65.260414]\n",
      " [72.49123 ]\n",
      " [45.604733]\n",
      " [67.07146 ]\n",
      " [68.415535]\n",
      " [42.206444]\n",
      " [40.97438 ]\n",
      " [64.9309  ]\n",
      " [73.28914 ]\n",
      " [68.87916 ]\n",
      " [62.074036]\n",
      " [54.021873]\n",
      " [39.495018]\n",
      " [63.926907]\n",
      " [55.235878]\n",
      " [46.41667 ]\n",
      " [63.97428 ]\n",
      " [61.892952]\n",
      " [60.015575]\n",
      " [62.8506  ]\n",
      " [62.257042]\n",
      " [65.94771 ]\n",
      " [55.841896]\n",
      " [51.70161 ]\n",
      " [62.335552]\n",
      " [72.639465]\n",
      " [61.421883]\n",
      " [45.49151 ]\n",
      " [57.70807 ]\n",
      " [64.39366 ]\n",
      " [49.96189 ]\n",
      " [52.943813]\n",
      " [65.99477 ]\n",
      " [45.053802]\n",
      " [63.26612 ]\n",
      " [64.35472 ]\n",
      " [64.39198 ]\n",
      " [61.61534 ]\n",
      " [39.393383]\n",
      " [65.31154 ]\n",
      " [70.25133 ]\n",
      " [48.057068]\n",
      " [57.51619 ]]\n",
      "epoch 0  | loss: 4397.90774|  0:00:00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1  | loss: 4196.63348|  0:00:00s\n",
      "epoch 2  | loss: 3984.66448|  0:00:00s\n",
      "epoch 3  | loss: 3629.802|  0:00:00s\n",
      "epoch 4  | loss: 3191.74475|  0:00:00s\n",
      "epoch 5  | loss: 2742.633|  0:00:00s\n",
      "epoch 6  | loss: 2269.72274|  0:00:00s\n",
      "epoch 7  | loss: 1797.85631|  0:00:01s\n",
      "epoch 8  | loss: 1321.59056|  0:00:01s\n",
      "epoch 9  | loss: 976.41094|  0:00:01s\n",
      "epoch 10 | loss: 780.61959|  0:00:01s\n",
      "epoch 11 | loss: 801.84314|  0:00:01s\n",
      "epoch 12 | loss: 811.36636|  0:00:01s\n",
      "epoch 13 | loss: 759.73252|  0:00:01s\n",
      "epoch 14 | loss: 786.42105|  0:00:02s\n",
      "epoch 15 | loss: 794.60438|  0:00:02s\n",
      "epoch 16 | loss: 740.71549|  0:00:02s\n",
      "epoch 17 | loss: 727.40713|  0:00:02s\n",
      "epoch 18 | loss: 715.36705|  0:00:02s\n",
      "epoch 19 | loss: 751.5827|  0:00:02s\n",
      "epoch 20 | loss: 703.35951|  0:00:02s\n",
      "epoch 21 | loss: 716.41525|  0:00:03s\n",
      "epoch 22 | loss: 719.94046|  0:00:03s\n",
      "epoch 23 | loss: 775.68696|  0:00:03s\n",
      "epoch 24 | loss: 771.61884|  0:00:03s\n",
      "epoch 25 | loss: 743.52702|  0:00:03s\n",
      "epoch 26 | loss: 724.95006|  0:00:03s\n",
      "epoch 27 | loss: 741.01899|  0:00:03s\n",
      "epoch 28 | loss: 705.19567|  0:00:04s\n",
      "epoch 29 | loss: 757.00736|  0:00:04s\n",
      "epoch 30 | loss: 753.09489|  0:00:04s\n",
      "epoch 31 | loss: 734.26999|  0:00:04s\n",
      "epoch 32 | loss: 731.92625|  0:00:04s\n",
      "epoch 33 | loss: 779.53157|  0:00:04s\n",
      "epoch 34 | loss: 724.37099|  0:00:04s\n",
      "epoch 35 | loss: 768.26521|  0:00:05s\n",
      "epoch 36 | loss: 724.71261|  0:00:05s\n",
      "epoch 37 | loss: 724.32319|  0:00:05s\n",
      "epoch 38 | loss: 719.02325|  0:00:05s\n",
      "epoch 39 | loss: 734.30492|  0:00:05s\n",
      "epoch 40 | loss: 685.54166|  0:00:05s\n",
      "epoch 41 | loss: 716.52336|  0:00:05s\n",
      "epoch 42 | loss: 719.90929|  0:00:05s\n",
      "epoch 43 | loss: 739.47737|  0:00:06s\n",
      "epoch 44 | loss: 763.25443|  0:00:06s\n",
      "epoch 45 | loss: 739.28486|  0:00:06s\n",
      "epoch 46 | loss: 727.52026|  0:00:06s\n",
      "epoch 47 | loss: 700.64676|  0:00:06s\n",
      "epoch 48 | loss: 757.86256|  0:00:06s\n",
      "epoch 49 | loss: 692.18711|  0:00:06s\n",
      "{'augmentations': <pytorch_tabnet.augmentations.RegressionSMOTE object at 0x12c1496a0>, 'batch_size': 64, 'drop_last': False, 'eval_metric': 'rmse', 'max_epochs': 50, 'num_workers': 0, 'patience': 50, 'virtual_batch_size': 128}\n",
      "[[53.78263 ]\n",
      " [54.9645  ]\n",
      " [42.141117]\n",
      " [55.10234 ]\n",
      " [44.27191 ]\n",
      " [60.75295 ]\n",
      " [48.03528 ]\n",
      " [52.85299 ]\n",
      " [37.5543  ]\n",
      " [52.449722]\n",
      " [46.62123 ]\n",
      " [56.582417]\n",
      " [64.85402 ]\n",
      " [57.39863 ]\n",
      " [65.96969 ]\n",
      " [51.413227]\n",
      " [70.48868 ]\n",
      " [52.41567 ]\n",
      " [54.70887 ]\n",
      " [56.36674 ]\n",
      " [56.046173]\n",
      " [51.959526]\n",
      " [61.59387 ]\n",
      " [53.259678]\n",
      " [49.12892 ]\n",
      " [51.406967]\n",
      " [46.68634 ]\n",
      " [57.007725]\n",
      " [66.16075 ]\n",
      " [42.74978 ]\n",
      " [55.09777 ]\n",
      " [41.91529 ]\n",
      " [57.74404 ]\n",
      " [56.40744 ]\n",
      " [76.143364]\n",
      " [50.038662]\n",
      " [50.98883 ]\n",
      " [70.91887 ]\n",
      " [58.76926 ]\n",
      " [56.435867]\n",
      " [48.52066 ]\n",
      " [57.63659 ]\n",
      " [55.79591 ]\n",
      " [50.94585 ]\n",
      " [55.955635]\n",
      " [53.967094]\n",
      " [68.93652 ]\n",
      " [56.363792]\n",
      " [40.864887]\n",
      " [57.750996]\n",
      " [51.214565]\n",
      " [49.59459 ]\n",
      " [56.836697]\n",
      " [55.34779 ]\n",
      " [45.3913  ]\n",
      " [51.97662 ]\n",
      " [44.990288]\n",
      " [46.71846 ]\n",
      " [54.18836 ]\n",
      " [58.9013  ]\n",
      " [65.29375 ]\n",
      " [47.63154 ]\n",
      " [58.322266]\n",
      " [70.250824]\n",
      " [57.538334]\n",
      " [52.32326 ]\n",
      " [38.526413]\n",
      " [56.073288]\n",
      " [48.973053]\n",
      " [54.86682 ]\n",
      " [53.354218]\n",
      " [54.81166 ]\n",
      " [54.29847 ]\n",
      " [72.204094]\n",
      " [52.76483 ]\n",
      " [39.734573]\n",
      " [43.901184]\n",
      " [49.977417]\n",
      " [66.597   ]\n",
      " [41.655975]\n",
      " [45.14468 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4397.90774|  0:00:00s\n",
      "epoch 1  | loss: 4196.63348|  0:00:00s\n",
      "epoch 2  | loss: 3984.66448|  0:00:00s\n",
      "epoch 3  | loss: 3629.802|  0:00:00s\n",
      "epoch 4  | loss: 3191.74475|  0:00:00s\n",
      "epoch 5  | loss: 2742.633|  0:00:00s\n",
      "epoch 6  | loss: 2269.72274|  0:00:01s\n",
      "epoch 7  | loss: 1797.85631|  0:00:01s\n",
      "epoch 8  | loss: 1321.59056|  0:00:01s\n",
      "epoch 9  | loss: 976.41094|  0:00:01s\n",
      "epoch 10 | loss: 780.61959|  0:00:01s\n",
      "epoch 11 | loss: 801.84314|  0:00:01s\n",
      "epoch 12 | loss: 811.36636|  0:00:01s\n",
      "epoch 13 | loss: 759.73252|  0:00:01s\n",
      "epoch 14 | loss: 786.42105|  0:00:02s\n",
      "epoch 15 | loss: 794.60438|  0:00:02s\n",
      "epoch 16 | loss: 740.71549|  0:00:02s\n",
      "epoch 17 | loss: 727.40713|  0:00:02s\n",
      "epoch 18 | loss: 715.36705|  0:00:02s\n",
      "epoch 19 | loss: 751.5827|  0:00:02s\n",
      "epoch 20 | loss: 703.35951|  0:00:02s\n",
      "epoch 21 | loss: 716.41525|  0:00:02s\n",
      "epoch 22 | loss: 719.94046|  0:00:03s\n",
      "epoch 23 | loss: 775.68696|  0:00:03s\n",
      "epoch 24 | loss: 771.61884|  0:00:03s\n",
      "epoch 25 | loss: 743.52702|  0:00:03s\n",
      "epoch 26 | loss: 724.95006|  0:00:03s\n",
      "epoch 27 | loss: 741.01899|  0:00:03s\n",
      "epoch 28 | loss: 705.19567|  0:00:03s\n",
      "epoch 29 | loss: 757.00736|  0:00:03s\n",
      "epoch 30 | loss: 753.09489|  0:00:04s\n",
      "epoch 31 | loss: 734.26999|  0:00:04s\n",
      "epoch 32 | loss: 731.92625|  0:00:04s\n",
      "epoch 33 | loss: 779.53157|  0:00:04s\n",
      "epoch 34 | loss: 724.37099|  0:00:04s\n",
      "epoch 35 | loss: 768.26521|  0:00:04s\n",
      "epoch 36 | loss: 724.71261|  0:00:04s\n",
      "epoch 37 | loss: 724.32319|  0:00:04s\n",
      "epoch 38 | loss: 719.02325|  0:00:04s\n",
      "epoch 39 | loss: 734.30492|  0:00:05s\n",
      "epoch 40 | loss: 685.54166|  0:00:05s\n",
      "epoch 41 | loss: 716.52336|  0:00:05s\n",
      "epoch 42 | loss: 719.90929|  0:00:05s\n",
      "epoch 43 | loss: 739.47737|  0:00:05s\n",
      "epoch 44 | loss: 763.25443|  0:00:05s\n",
      "epoch 45 | loss: 739.28486|  0:00:05s\n",
      "epoch 46 | loss: 727.52026|  0:00:05s\n",
      "epoch 47 | loss: 700.64676|  0:00:06s\n",
      "epoch 48 | loss: 757.86256|  0:00:06s\n",
      "epoch 49 | loss: 692.18711|  0:00:06s\n",
      "{'augmentations': <pytorch_tabnet.augmentations.RegressionSMOTE object at 0x12c1496a0>, 'batch_size': 64, 'drop_last': False, 'eval_metric': 'rmse', 'max_epochs': 50, 'num_workers': 0, 'patience': 100, 'virtual_batch_size': 128}\n",
      "[[53.78263 ]\n",
      " [54.9645  ]\n",
      " [42.141117]\n",
      " [55.10234 ]\n",
      " [44.27191 ]\n",
      " [60.75295 ]\n",
      " [48.03528 ]\n",
      " [52.85299 ]\n",
      " [37.5543  ]\n",
      " [52.449722]\n",
      " [46.62123 ]\n",
      " [56.582417]\n",
      " [64.85402 ]\n",
      " [57.39863 ]\n",
      " [65.96969 ]\n",
      " [51.413227]\n",
      " [70.48868 ]\n",
      " [52.41567 ]\n",
      " [54.70887 ]\n",
      " [56.36674 ]\n",
      " [56.046173]\n",
      " [51.959526]\n",
      " [61.59387 ]\n",
      " [53.259678]\n",
      " [49.12892 ]\n",
      " [51.406967]\n",
      " [46.68634 ]\n",
      " [57.007725]\n",
      " [66.16075 ]\n",
      " [42.74978 ]\n",
      " [55.09777 ]\n",
      " [41.91529 ]\n",
      " [57.74404 ]\n",
      " [56.40744 ]\n",
      " [76.143364]\n",
      " [50.038662]\n",
      " [50.98883 ]\n",
      " [70.91887 ]\n",
      " [58.76926 ]\n",
      " [56.435867]\n",
      " [48.52066 ]\n",
      " [57.63659 ]\n",
      " [55.79591 ]\n",
      " [50.94585 ]\n",
      " [55.955635]\n",
      " [53.967094]\n",
      " [68.93652 ]\n",
      " [56.363792]\n",
      " [40.864887]\n",
      " [57.750996]\n",
      " [51.214565]\n",
      " [49.59459 ]\n",
      " [56.836697]\n",
      " [55.34779 ]\n",
      " [45.3913  ]\n",
      " [51.97662 ]\n",
      " [44.990288]\n",
      " [46.71846 ]\n",
      " [54.18836 ]\n",
      " [58.9013  ]\n",
      " [65.29375 ]\n",
      " [47.63154 ]\n",
      " [58.322266]\n",
      " [70.250824]\n",
      " [57.538334]\n",
      " [52.32326 ]\n",
      " [38.526413]\n",
      " [56.073288]\n",
      " [48.973053]\n",
      " [54.86682 ]\n",
      " [53.354218]\n",
      " [54.81166 ]\n",
      " [54.29847 ]\n",
      " [72.204094]\n",
      " [52.76483 ]\n",
      " [39.734573]\n",
      " [43.901184]\n",
      " [49.977417]\n",
      " [66.597   ]\n",
      " [41.655975]\n",
      " [45.14468 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4397.90774|  0:00:00s\n",
      "epoch 1  | loss: 4196.63348|  0:00:00s\n",
      "epoch 2  | loss: 3984.66448|  0:00:00s\n",
      "epoch 3  | loss: 3629.802|  0:00:00s\n",
      "epoch 4  | loss: 3191.74475|  0:00:00s\n",
      "epoch 5  | loss: 2742.633|  0:00:00s\n",
      "epoch 6  | loss: 2269.72274|  0:00:00s\n",
      "epoch 7  | loss: 1797.85631|  0:00:01s\n",
      "epoch 8  | loss: 1321.59056|  0:00:01s\n",
      "epoch 9  | loss: 976.41094|  0:00:01s\n",
      "epoch 10 | loss: 780.61959|  0:00:01s\n",
      "epoch 11 | loss: 801.84314|  0:00:01s\n",
      "epoch 12 | loss: 811.36636|  0:00:01s\n",
      "epoch 13 | loss: 759.73252|  0:00:01s\n",
      "epoch 14 | loss: 786.42105|  0:00:01s\n",
      "epoch 15 | loss: 794.60438|  0:00:02s\n",
      "epoch 16 | loss: 740.71549|  0:00:02s\n",
      "epoch 17 | loss: 727.40713|  0:00:02s\n",
      "epoch 18 | loss: 715.36705|  0:00:02s\n",
      "epoch 19 | loss: 751.5827|  0:00:02s\n",
      "epoch 20 | loss: 703.35951|  0:00:02s\n",
      "epoch 21 | loss: 716.41525|  0:00:02s\n",
      "epoch 22 | loss: 719.94046|  0:00:02s\n",
      "epoch 23 | loss: 775.68696|  0:00:03s\n",
      "epoch 24 | loss: 771.61884|  0:00:03s\n",
      "epoch 25 | loss: 743.52702|  0:00:03s\n",
      "epoch 26 | loss: 724.95006|  0:00:03s\n",
      "epoch 27 | loss: 741.01899|  0:00:03s\n",
      "epoch 28 | loss: 705.19567|  0:00:03s\n",
      "epoch 29 | loss: 757.00736|  0:00:03s\n",
      "epoch 30 | loss: 753.09489|  0:00:03s\n",
      "epoch 31 | loss: 734.26999|  0:00:04s\n",
      "epoch 32 | loss: 731.92625|  0:00:04s\n",
      "epoch 33 | loss: 779.53157|  0:00:04s\n",
      "epoch 34 | loss: 724.37099|  0:00:04s\n",
      "epoch 35 | loss: 768.26521|  0:00:04s\n",
      "epoch 36 | loss: 724.71261|  0:00:04s\n",
      "epoch 37 | loss: 724.32319|  0:00:04s\n",
      "epoch 38 | loss: 719.02325|  0:00:04s\n",
      "epoch 39 | loss: 734.30492|  0:00:05s\n",
      "epoch 40 | loss: 685.54166|  0:00:05s\n",
      "epoch 41 | loss: 716.52336|  0:00:05s\n",
      "epoch 42 | loss: 719.90929|  0:00:05s\n",
      "epoch 43 | loss: 739.47737|  0:00:05s\n",
      "epoch 44 | loss: 763.25443|  0:00:05s\n",
      "epoch 45 | loss: 739.28486|  0:00:05s\n",
      "epoch 46 | loss: 727.52026|  0:00:05s\n",
      "epoch 47 | loss: 700.64676|  0:00:05s\n",
      "epoch 48 | loss: 757.86256|  0:00:06s\n",
      "epoch 49 | loss: 692.18711|  0:00:06s\n",
      "{'augmentations': <pytorch_tabnet.augmentations.RegressionSMOTE object at 0x12c1496a0>, 'batch_size': 64, 'drop_last': False, 'eval_metric': 'rmse', 'max_epochs': 50, 'num_workers': 0, 'patience': 150, 'virtual_batch_size': 128}\n",
      "[[53.78263 ]\n",
      " [54.9645  ]\n",
      " [42.141117]\n",
      " [55.10234 ]\n",
      " [44.27191 ]\n",
      " [60.75295 ]\n",
      " [48.03528 ]\n",
      " [52.85299 ]\n",
      " [37.5543  ]\n",
      " [52.449722]\n",
      " [46.62123 ]\n",
      " [56.582417]\n",
      " [64.85402 ]\n",
      " [57.39863 ]\n",
      " [65.96969 ]\n",
      " [51.413227]\n",
      " [70.48868 ]\n",
      " [52.41567 ]\n",
      " [54.70887 ]\n",
      " [56.36674 ]\n",
      " [56.046173]\n",
      " [51.959526]\n",
      " [61.59387 ]\n",
      " [53.259678]\n",
      " [49.12892 ]\n",
      " [51.406967]\n",
      " [46.68634 ]\n",
      " [57.007725]\n",
      " [66.16075 ]\n",
      " [42.74978 ]\n",
      " [55.09777 ]\n",
      " [41.91529 ]\n",
      " [57.74404 ]\n",
      " [56.40744 ]\n",
      " [76.143364]\n",
      " [50.038662]\n",
      " [50.98883 ]\n",
      " [70.91887 ]\n",
      " [58.76926 ]\n",
      " [56.435867]\n",
      " [48.52066 ]\n",
      " [57.63659 ]\n",
      " [55.79591 ]\n",
      " [50.94585 ]\n",
      " [55.955635]\n",
      " [53.967094]\n",
      " [68.93652 ]\n",
      " [56.363792]\n",
      " [40.864887]\n",
      " [57.750996]\n",
      " [51.214565]\n",
      " [49.59459 ]\n",
      " [56.836697]\n",
      " [55.34779 ]\n",
      " [45.3913  ]\n",
      " [51.97662 ]\n",
      " [44.990288]\n",
      " [46.71846 ]\n",
      " [54.18836 ]\n",
      " [58.9013  ]\n",
      " [65.29375 ]\n",
      " [47.63154 ]\n",
      " [58.322266]\n",
      " [70.250824]\n",
      " [57.538334]\n",
      " [52.32326 ]\n",
      " [38.526413]\n",
      " [56.073288]\n",
      " [48.973053]\n",
      " [54.86682 ]\n",
      " [53.354218]\n",
      " [54.81166 ]\n",
      " [54.29847 ]\n",
      " [72.204094]\n",
      " [52.76483 ]\n",
      " [39.734573]\n",
      " [43.901184]\n",
      " [49.977417]\n",
      " [66.597   ]\n",
      " [41.655975]\n",
      " [45.14468 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4397.90774|  0:00:00s\n",
      "epoch 1  | loss: 4196.63348|  0:00:00s\n",
      "epoch 2  | loss: 3984.66448|  0:00:00s\n",
      "epoch 3  | loss: 3629.802|  0:00:00s\n",
      "epoch 4  | loss: 3191.74475|  0:00:01s\n",
      "epoch 5  | loss: 2742.633|  0:00:01s\n",
      "epoch 6  | loss: 2269.72274|  0:00:01s\n",
      "epoch 7  | loss: 1797.85631|  0:00:02s\n",
      "epoch 8  | loss: 1321.59056|  0:00:02s\n",
      "epoch 9  | loss: 976.41094|  0:00:02s\n",
      "epoch 10 | loss: 780.61959|  0:00:02s\n",
      "epoch 11 | loss: 801.84314|  0:00:02s\n",
      "epoch 12 | loss: 811.36636|  0:00:03s\n",
      "epoch 13 | loss: 759.73252|  0:00:03s\n",
      "epoch 14 | loss: 786.42105|  0:00:03s\n",
      "epoch 15 | loss: 794.60438|  0:00:03s\n",
      "epoch 16 | loss: 740.71549|  0:00:03s\n",
      "epoch 17 | loss: 727.40713|  0:00:04s\n",
      "epoch 18 | loss: 715.36705|  0:00:04s\n",
      "epoch 19 | loss: 751.5827|  0:00:04s\n",
      "epoch 20 | loss: 703.35951|  0:00:04s\n",
      "epoch 21 | loss: 716.41525|  0:00:04s\n",
      "epoch 22 | loss: 719.94046|  0:00:05s\n",
      "epoch 23 | loss: 775.68696|  0:00:05s\n",
      "epoch 24 | loss: 771.61884|  0:00:05s\n",
      "epoch 25 | loss: 743.52702|  0:00:05s\n",
      "epoch 26 | loss: 724.95006|  0:00:05s\n",
      "epoch 27 | loss: 741.01899|  0:00:06s\n",
      "epoch 28 | loss: 705.19567|  0:00:06s\n",
      "epoch 29 | loss: 757.00736|  0:00:06s\n",
      "epoch 30 | loss: 753.09489|  0:00:06s\n",
      "epoch 31 | loss: 734.26999|  0:00:07s\n",
      "epoch 32 | loss: 731.92625|  0:00:07s\n",
      "epoch 33 | loss: 779.53157|  0:00:07s\n",
      "epoch 34 | loss: 724.37099|  0:00:07s\n",
      "epoch 35 | loss: 768.26521|  0:00:07s\n",
      "epoch 36 | loss: 724.71261|  0:00:08s\n",
      "epoch 37 | loss: 724.32319|  0:00:08s\n",
      "epoch 38 | loss: 719.02325|  0:00:08s\n",
      "epoch 39 | loss: 734.30492|  0:00:08s\n",
      "epoch 40 | loss: 685.54166|  0:00:09s\n",
      "epoch 41 | loss: 716.52336|  0:00:09s\n",
      "epoch 42 | loss: 719.90929|  0:00:09s\n",
      "epoch 43 | loss: 739.47737|  0:00:09s\n",
      "epoch 44 | loss: 763.25443|  0:00:09s\n",
      "epoch 45 | loss: 739.28486|  0:00:10s\n",
      "epoch 46 | loss: 727.52026|  0:00:10s\n",
      "epoch 47 | loss: 700.64676|  0:00:10s\n",
      "epoch 48 | loss: 757.86256|  0:00:10s\n",
      "epoch 49 | loss: 692.18711|  0:00:11s\n",
      "{'augmentations': <pytorch_tabnet.augmentations.RegressionSMOTE object at 0x12c1496a0>, 'batch_size': 64, 'drop_last': False, 'eval_metric': 'rmse', 'max_epochs': 50, 'num_workers': 1, 'patience': 50, 'virtual_batch_size': 128}\n",
      "[[53.78263 ]\n",
      " [54.9645  ]\n",
      " [42.141117]\n",
      " [55.10234 ]\n",
      " [44.27191 ]\n",
      " [60.75295 ]\n",
      " [48.03528 ]\n",
      " [52.85299 ]\n",
      " [37.5543  ]\n",
      " [52.449722]\n",
      " [46.62123 ]\n",
      " [56.582417]\n",
      " [64.85402 ]\n",
      " [57.39863 ]\n",
      " [65.96969 ]\n",
      " [51.413227]\n",
      " [70.48868 ]\n",
      " [52.41567 ]\n",
      " [54.70887 ]\n",
      " [56.36674 ]\n",
      " [56.046173]\n",
      " [51.959526]\n",
      " [61.59387 ]\n",
      " [53.259678]\n",
      " [49.12892 ]\n",
      " [51.406967]\n",
      " [46.68634 ]\n",
      " [57.007725]\n",
      " [66.16075 ]\n",
      " [42.74978 ]\n",
      " [55.09777 ]\n",
      " [41.91529 ]\n",
      " [57.74404 ]\n",
      " [56.40744 ]\n",
      " [76.143364]\n",
      " [50.038662]\n",
      " [50.98883 ]\n",
      " [70.91887 ]\n",
      " [58.76926 ]\n",
      " [56.435867]\n",
      " [48.52066 ]\n",
      " [57.63659 ]\n",
      " [55.79591 ]\n",
      " [50.94585 ]\n",
      " [55.955635]\n",
      " [53.967094]\n",
      " [68.93652 ]\n",
      " [56.363792]\n",
      " [40.864887]\n",
      " [57.750996]\n",
      " [51.214565]\n",
      " [49.59459 ]\n",
      " [56.836697]\n",
      " [55.34779 ]\n",
      " [45.3913  ]\n",
      " [51.97662 ]\n",
      " [44.990288]\n",
      " [46.71846 ]\n",
      " [54.18836 ]\n",
      " [58.9013  ]\n",
      " [65.29375 ]\n",
      " [47.63154 ]\n",
      " [58.322266]\n",
      " [70.250824]\n",
      " [57.538334]\n",
      " [52.32326 ]\n",
      " [38.526413]\n",
      " [56.073288]\n",
      " [48.973053]\n",
      " [54.86682 ]\n",
      " [53.354218]\n",
      " [54.81166 ]\n",
      " [54.29847 ]\n",
      " [72.204094]\n",
      " [52.76483 ]\n",
      " [39.734573]\n",
      " [43.901184]\n",
      " [49.977417]\n",
      " [66.597   ]\n",
      " [41.655975]\n",
      " [45.14468 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4397.90774|  0:00:00s\n",
      "epoch 1  | loss: 4196.63348|  0:00:00s\n",
      "epoch 2  | loss: 3984.66448|  0:00:00s\n",
      "epoch 3  | loss: 3629.802|  0:00:00s\n",
      "epoch 4  | loss: 3191.74475|  0:00:01s\n",
      "epoch 5  | loss: 2742.633|  0:00:01s\n",
      "epoch 6  | loss: 2269.72274|  0:00:01s\n",
      "epoch 7  | loss: 1797.85631|  0:00:01s\n",
      "epoch 8  | loss: 1321.59056|  0:00:01s\n",
      "epoch 9  | loss: 976.41094|  0:00:02s\n",
      "epoch 10 | loss: 780.61959|  0:00:02s\n",
      "epoch 11 | loss: 801.84314|  0:00:02s\n",
      "epoch 12 | loss: 811.36636|  0:00:02s\n",
      "epoch 13 | loss: 759.73252|  0:00:02s\n",
      "epoch 14 | loss: 786.42105|  0:00:03s\n",
      "epoch 15 | loss: 794.60438|  0:00:03s\n",
      "epoch 16 | loss: 740.71549|  0:00:03s\n",
      "epoch 17 | loss: 727.40713|  0:00:03s\n",
      "epoch 18 | loss: 715.36705|  0:00:03s\n",
      "epoch 19 | loss: 751.5827|  0:00:04s\n",
      "epoch 20 | loss: 703.35951|  0:00:04s\n",
      "epoch 21 | loss: 716.41525|  0:00:04s\n",
      "epoch 22 | loss: 719.94046|  0:00:04s\n",
      "epoch 23 | loss: 775.68696|  0:00:05s\n",
      "epoch 24 | loss: 771.61884|  0:00:05s\n",
      "epoch 25 | loss: 743.52702|  0:00:05s\n",
      "epoch 26 | loss: 724.95006|  0:00:05s\n",
      "epoch 27 | loss: 741.01899|  0:00:05s\n",
      "epoch 28 | loss: 705.19567|  0:00:06s\n",
      "epoch 29 | loss: 757.00736|  0:00:06s\n",
      "epoch 30 | loss: 753.09489|  0:00:06s\n",
      "epoch 31 | loss: 734.26999|  0:00:06s\n",
      "epoch 32 | loss: 731.92625|  0:00:07s\n",
      "epoch 33 | loss: 779.53157|  0:00:07s\n",
      "epoch 34 | loss: 724.37099|  0:00:07s\n",
      "epoch 35 | loss: 768.26521|  0:00:07s\n",
      "epoch 36 | loss: 724.71261|  0:00:07s\n",
      "epoch 37 | loss: 724.32319|  0:00:08s\n",
      "epoch 38 | loss: 719.02325|  0:00:08s\n",
      "epoch 39 | loss: 734.30492|  0:00:08s\n",
      "epoch 40 | loss: 685.54166|  0:00:08s\n",
      "epoch 41 | loss: 716.52336|  0:00:08s\n",
      "epoch 42 | loss: 719.90929|  0:00:09s\n",
      "epoch 43 | loss: 739.47737|  0:00:09s\n",
      "epoch 44 | loss: 763.25443|  0:00:09s\n",
      "epoch 45 | loss: 739.28486|  0:00:09s\n",
      "epoch 46 | loss: 727.52026|  0:00:09s\n",
      "epoch 47 | loss: 700.64676|  0:00:10s\n",
      "epoch 48 | loss: 757.86256|  0:00:10s\n",
      "epoch 49 | loss: 692.18711|  0:00:10s\n",
      "{'augmentations': <pytorch_tabnet.augmentations.RegressionSMOTE object at 0x12c1496a0>, 'batch_size': 64, 'drop_last': False, 'eval_metric': 'rmse', 'max_epochs': 50, 'num_workers': 1, 'patience': 100, 'virtual_batch_size': 128}\n",
      "[[53.78263 ]\n",
      " [54.9645  ]\n",
      " [42.141117]\n",
      " [55.10234 ]\n",
      " [44.27191 ]\n",
      " [60.75295 ]\n",
      " [48.03528 ]\n",
      " [52.85299 ]\n",
      " [37.5543  ]\n",
      " [52.449722]\n",
      " [46.62123 ]\n",
      " [56.582417]\n",
      " [64.85402 ]\n",
      " [57.39863 ]\n",
      " [65.96969 ]\n",
      " [51.413227]\n",
      " [70.48868 ]\n",
      " [52.41567 ]\n",
      " [54.70887 ]\n",
      " [56.36674 ]\n",
      " [56.046173]\n",
      " [51.959526]\n",
      " [61.59387 ]\n",
      " [53.259678]\n",
      " [49.12892 ]\n",
      " [51.406967]\n",
      " [46.68634 ]\n",
      " [57.007725]\n",
      " [66.16075 ]\n",
      " [42.74978 ]\n",
      " [55.09777 ]\n",
      " [41.91529 ]\n",
      " [57.74404 ]\n",
      " [56.40744 ]\n",
      " [76.143364]\n",
      " [50.038662]\n",
      " [50.98883 ]\n",
      " [70.91887 ]\n",
      " [58.76926 ]\n",
      " [56.435867]\n",
      " [48.52066 ]\n",
      " [57.63659 ]\n",
      " [55.79591 ]\n",
      " [50.94585 ]\n",
      " [55.955635]\n",
      " [53.967094]\n",
      " [68.93652 ]\n",
      " [56.363792]\n",
      " [40.864887]\n",
      " [57.750996]\n",
      " [51.214565]\n",
      " [49.59459 ]\n",
      " [56.836697]\n",
      " [55.34779 ]\n",
      " [45.3913  ]\n",
      " [51.97662 ]\n",
      " [44.990288]\n",
      " [46.71846 ]\n",
      " [54.18836 ]\n",
      " [58.9013  ]\n",
      " [65.29375 ]\n",
      " [47.63154 ]\n",
      " [58.322266]\n",
      " [70.250824]\n",
      " [57.538334]\n",
      " [52.32326 ]\n",
      " [38.526413]\n",
      " [56.073288]\n",
      " [48.973053]\n",
      " [54.86682 ]\n",
      " [53.354218]\n",
      " [54.81166 ]\n",
      " [54.29847 ]\n",
      " [72.204094]\n",
      " [52.76483 ]\n",
      " [39.734573]\n",
      " [43.901184]\n",
      " [49.977417]\n",
      " [66.597   ]\n",
      " [41.655975]\n",
      " [45.14468 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/Users/renan/Library/Python/3.7/lib/python/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4397.90774|  0:00:00s\n",
      "epoch 1  | loss: 4196.63348|  0:00:00s\n",
      "epoch 2  | loss: 3984.66448|  0:00:00s\n",
      "epoch 3  | loss: 3629.802|  0:00:00s\n",
      "epoch 4  | loss: 3191.74475|  0:00:01s\n",
      "epoch 5  | loss: 2742.633|  0:00:01s\n",
      "epoch 6  | loss: 2269.72274|  0:00:01s\n",
      "epoch 7  | loss: 1797.85631|  0:00:01s\n",
      "epoch 8  | loss: 1321.59056|  0:00:01s\n",
      "epoch 9  | loss: 976.41094|  0:00:02s\n",
      "epoch 10 | loss: 780.61959|  0:00:02s\n",
      "epoch 11 | loss: 801.84314|  0:00:02s\n",
      "epoch 12 | loss: 811.36636|  0:00:02s\n",
      "epoch 13 | loss: 759.73252|  0:00:02s\n",
      "epoch 14 | loss: 786.42105|  0:00:03s\n",
      "epoch 15 | loss: 794.60438|  0:00:03s\n",
      "epoch 16 | loss: 740.71549|  0:00:03s\n",
      "epoch 17 | loss: 727.40713|  0:00:03s\n",
      "epoch 18 | loss: 715.36705|  0:00:03s\n",
      "epoch 19 | loss: 751.5827|  0:00:04s\n",
      "epoch 20 | loss: 703.35951|  0:00:04s\n",
      "epoch 21 | loss: 716.41525|  0:00:04s\n",
      "epoch 22 | loss: 719.94046|  0:00:04s\n",
      "epoch 23 | loss: 775.68696|  0:00:04s\n",
      "epoch 24 | loss: 771.61884|  0:00:05s\n",
      "epoch 25 | loss: 743.52702|  0:00:05s\n",
      "epoch 26 | loss: 724.95006|  0:00:05s\n",
      "epoch 27 | loss: 741.01899|  0:00:05s\n",
      "epoch 28 | loss: 705.19567|  0:00:05s\n",
      "epoch 29 | loss: 757.00736|  0:00:06s\n",
      "epoch 30 | loss: 753.09489|  0:00:06s\n",
      "epoch 31 | loss: 734.26999|  0:00:06s\n",
      "epoch 32 | loss: 731.92625|  0:00:06s\n",
      "epoch 33 | loss: 779.53157|  0:00:06s\n",
      "epoch 34 | loss: 724.37099|  0:00:07s\n",
      "epoch 35 | loss: 768.26521|  0:00:07s\n",
      "epoch 36 | loss: 724.71261|  0:00:07s\n",
      "epoch 37 | loss: 724.32319|  0:00:07s\n",
      "epoch 38 | loss: 719.02325|  0:00:07s\n",
      "epoch 39 | loss: 734.30492|  0:00:08s\n",
      "epoch 40 | loss: 685.54166|  0:00:08s\n",
      "epoch 41 | loss: 716.52336|  0:00:08s\n",
      "epoch 42 | loss: 719.90929|  0:00:08s\n",
      "epoch 43 | loss: 739.47737|  0:00:08s\n",
      "epoch 44 | loss: 763.25443|  0:00:09s\n",
      "epoch 45 | loss: 739.28486|  0:00:09s\n",
      "epoch 46 | loss: 727.52026|  0:00:09s\n",
      "epoch 47 | loss: 700.64676|  0:00:09s\n",
      "epoch 48 | loss: 757.86256|  0:00:09s\n",
      "epoch 49 | loss: 692.18711|  0:00:10s\n",
      "{'augmentations': <pytorch_tabnet.augmentations.RegressionSMOTE object at 0x12c1496a0>, 'batch_size': 64, 'drop_last': False, 'eval_metric': 'rmse', 'max_epochs': 50, 'num_workers': 1, 'patience': 150, 'virtual_batch_size': 128}\n",
      "[[53.78263 ]\n",
      " [54.9645  ]\n",
      " [42.141117]\n",
      " [55.10234 ]\n",
      " [44.27191 ]\n",
      " [60.75295 ]\n",
      " [48.03528 ]\n",
      " [52.85299 ]\n",
      " [37.5543  ]\n",
      " [52.449722]\n",
      " [46.62123 ]\n",
      " [56.582417]\n",
      " [64.85402 ]\n",
      " [57.39863 ]\n",
      " [65.96969 ]\n",
      " [51.413227]\n",
      " [70.48868 ]\n",
      " [52.41567 ]\n",
      " [54.70887 ]\n",
      " [56.36674 ]\n",
      " [56.046173]\n",
      " [51.959526]\n",
      " [61.59387 ]\n",
      " [53.259678]\n",
      " [49.12892 ]\n",
      " [51.406967]\n",
      " [46.68634 ]\n",
      " [57.007725]\n",
      " [66.16075 ]\n",
      " [42.74978 ]\n",
      " [55.09777 ]\n",
      " [41.91529 ]\n",
      " [57.74404 ]\n",
      " [56.40744 ]\n",
      " [76.143364]\n",
      " [50.038662]\n",
      " [50.98883 ]\n",
      " [70.91887 ]\n",
      " [58.76926 ]\n",
      " [56.435867]\n",
      " [48.52066 ]\n",
      " [57.63659 ]\n",
      " [55.79591 ]\n",
      " [50.94585 ]\n",
      " [55.955635]\n",
      " [53.967094]\n",
      " [68.93652 ]\n",
      " [56.363792]\n",
      " [40.864887]\n",
      " [57.750996]\n",
      " [51.214565]\n",
      " [49.59459 ]\n",
      " [56.836697]\n",
      " [55.34779 ]\n",
      " [45.3913  ]\n",
      " [51.97662 ]\n",
      " [44.990288]\n",
      " [46.71846 ]\n",
      " [54.18836 ]\n",
      " [58.9013  ]\n",
      " [65.29375 ]\n",
      " [47.63154 ]\n",
      " [58.322266]\n",
      " [70.250824]\n",
      " [57.538334]\n",
      " [52.32326 ]\n",
      " [38.526413]\n",
      " [56.073288]\n",
      " [48.973053]\n",
      " [54.86682 ]\n",
      " [53.354218]\n",
      " [54.81166 ]\n",
      " [54.29847 ]\n",
      " [72.204094]\n",
      " [52.76483 ]\n",
      " [39.734573]\n",
      " [43.901184]\n",
      " [49.977417]\n",
      " [66.597   ]\n",
      " [41.655975]\n",
      " [45.14468 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "hyper_params_grid = {\n",
    "    # 'eval_name':['train'],\n",
    "    'eval_metric':['rmse'],\n",
    "    'max_epochs':[max_epochs],\n",
    "    'patience':[50, 100, 150],\n",
    "    'batch_size':[1024, 64],\n",
    "    'virtual_batch_size':[128],\n",
    "    'num_workers':[0, 1],\n",
    "    'drop_last':[False],\n",
    "    'augmentations':[aug],\n",
    "}\n",
    "\n",
    "\n",
    "X_train = x_train_tf.numpy()\n",
    "y_train = y_train_tf.numpy()\n",
    "\n",
    "# Generate the parameter grid.\n",
    "param_grid = hyper_params_grid\n",
    "\n",
    "grid = ParameterGrid(param_grid)\n",
    "\n",
    "search_results = pd.DataFrame() \n",
    "for params in grid:\n",
    "    # params['n_a'] = params['n_d'] # n_a=n_d always per the paper\n",
    "    tabnet = TabNetRegressor(params=params)\n",
    "    #tabnet.set_params(**params)\n",
    "    tabnet.fit(X=X_train, y=y_train,\n",
    "               #X_valid=X_train, y_valid=y_train,\n",
    "            )\n",
    "\n",
    "    y_prob = tabnet.predict(X=x_test.to_numpy())\n",
    "    print(y_prob)\n",
    "    # score = accuracy_score(y_test, y_prob)\n",
    "    \n",
    "    # results = pd.DataFrame([params])\n",
    "    # results['score'] = np.round(score, 3)\n",
    "    # search_results = search_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
