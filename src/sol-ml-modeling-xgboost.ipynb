{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Scikit Learn libraries\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Scipy libraries\n",
    "from scipy import stats\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Utils functions\n",
    "from utils.utils import kfold, five_two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../data/\"\n",
    "\n",
    "data_path = folder_path + \"complex_processed_data.csv\"\n",
    "standardized_data_path = folder_path + 'complex_processed_standardized_data.csv'\n",
    "standardized_poutliers_removed_data_path = folder_path + 'complex_processed_standardized_outliers_removed_data.csv'\n",
    "\n",
    "df_solubility = pd.read_csv(standardized_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Dataset\n",
    "\n",
    "Process Dataset before the model creation.\n",
    "The following actions were done:\n",
    "* Split the independent variable from the dependent ones;\n",
    "* Split Dataset for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into X and Y for machine learning\n",
    "\n",
    "df_sol_X = df_solubility.copy()\n",
    "df_sol_X.drop(columns=['solubility'], axis=1, inplace=True)\n",
    "\n",
    "df_sol_y = df_solubility[['solubility']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                        df_sol_X, df_sol_y, \n",
    "                        train_size = 0.8,\n",
    "                        test_size = 0.2,\n",
    "                        random_state = 10\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting regression - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cross validation scheme to be used for train and test\n",
    "folds = kfold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 score on test set: 0.1356\n"
     ]
    }
   ],
   "source": [
    "# Create basic xgboost model\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 500,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"loss\": \"squared_error\",\n",
    "}\n",
    "\n",
    "xgboost = ensemble.GradientBoostingRegressor(**params)\n",
    "xgboost.fit(x_train, y_train)\n",
    "\n",
    "r2 = r2_score(y_test, xgboost.predict(x_test))\n",
    "print(\"The r2 score on test set: {:.4f}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 17280 candidates, totalling 172800 fits\n",
      "{'criterion': 'mse', 'learning_rate': 0.03, 'loss': 'squared_error', 'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Specify range of hyperparameters to tune\n",
    "hyper_params = {\n",
    "    'n_estimators':[100, 200, 300, 350, 400, 500],\n",
    "    'max_depth':[2, 3, 4, 5],\n",
    "    \"min_samples_split\": [1,2,3,4],\n",
    "    \"min_samples_leaf\": [1,1.5,2],\n",
    "    \"learning_rate\": [0.01,0.02,0.03,0.4,0.5],\n",
    "    \"loss\": [\"squared_error\", \"absolute_error\", \"huber\", \"quantile\"],\n",
    "    \"criterion\": [\"friedman_mse\", \"squared_error\", \"mse\"],\n",
    "    }\n",
    "\n",
    "\n",
    "# Call GridSearchCV()\n",
    "model_cv = GridSearchCV(\n",
    "    estimator = ensemble.GradientBoostingRegressor(),\n",
    "    param_grid = hyper_params,\n",
    "    scoring= 'r2',\n",
    "    cv = folds,\n",
    "    verbose = 1,\n",
    "    return_train_score=True,\n",
    "    n_jobs = -1,\n",
    "    refit = True\n",
    "    )\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "best_model = model_cv.fit(x_train, np.ravel(y_train)) \n",
    "\n",
    "print(model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new model with best_params_ from grid search\n",
    "# Use cross validation on the best_params_ model\n",
    "\n",
    "\n",
    "xgboost_best = ensemble.GradientBoostingRegressor(\n",
    "    n_estimators=model_cv.best_params_['n_estimators'],\n",
    "    max_depth=model_cv.best_params_['max_depth'],\n",
    "    min_samples_split=model_cv.best_params_['min_samples_split'],\n",
    "    min_samples_leaf=model_cv.best_params_['min_samples_leaf'],\n",
    "    learning_rate=model_cv.best_params_['learning_rate'],\n",
    "    loss=model_cv.best_params_['loss']\n",
    "    )\n",
    "\n",
    "xgboost_best.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 score on test set: 0.2585\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(y_test, xgboost_best.predict(x_test))\n",
    "print(\"The r2 score on test set: {:.4f}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/xgboost_model.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../models/xgboost_model.joblib'\n",
    "joblib.dump(xgboost_best, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare before and after gridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1 score difference = -0.003338\n",
      "Fold  2 score difference = -0.063062\n",
      "Fold  1 score difference = -0.141471\n",
      "Fold  2 score difference = -0.010327\n",
      "Fold  1 score difference = -0.126887\n",
      "Fold  2 score difference = -0.056949\n",
      "Fold  1 score difference = -0.031220\n",
      "Fold  2 score difference = -0.060850\n",
      "Fold  1 score difference = -0.040075\n",
      "Fold  2 score difference = -0.132171\n",
      "Regression 1 mean score and stdev : 0.131289 + 0.050382\n",
      "Regression 2 mean score and stdev : 0.197924 + 0.039552\n",
      "Score difference mean + stdev : -0.066635 + 0.047752\n",
      "t_value for the current test is -0.056402\n"
     ]
    }
   ],
   "source": [
    "five_two(\n",
    "    reg1=xgboost,\n",
    "    reg2=xgboost_best,\n",
    "    X=df_sol_X,\n",
    "    y=df_sol_y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.20218046,  0.25680103,  0.24075854,  0.34294074,  0.24914948,\n",
       "        0.26067139, -0.15171532,  0.15028745,  0.26910739,  0.20538644])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(estimator=xgboost_best, X=df_sol_X, y=df_sol_y, cv=folds, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10321528,  0.15026094,  0.18005148,  0.12085832,  0.21122356,\n",
       "        0.22748294, -0.30682261,  0.10017498,  0.1331599 ,  0.15394367])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(estimator=xgboost, X=df_sol_X, y=df_sol_y, cv=folds, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1 score difference = -0.050991\n",
      "Fold  2 score difference = -0.029920\n",
      "Fold  1 score difference = 0.092379\n",
      "Fold  2 score difference = -0.093822\n",
      "Fold  1 score difference = -0.336986\n",
      "Fold  2 score difference = -0.150148\n",
      "Fold  1 score difference = 0.086856\n",
      "Fold  2 score difference = -0.077419\n",
      "Fold  1 score difference = -0.213519\n",
      "Fold  2 score difference = -0.030706\n",
      "Regression 1 mean score and stdev : 0.004064 + 0.199994\n",
      "Regression 2 mean score and stdev : 0.084492 + 0.168357\n",
      "Score difference mean + stdev : -0.080428 + 0.123418\n",
      "t_value for the current test is -0.446487\n"
     ]
    }
   ],
   "source": [
    "five_two(\n",
    "    reg1=xgboost,\n",
    "    reg2=xgboost_best,\n",
    "    X=x_test,\n",
    "    y=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.44776424,  0.47917305,  0.47277477, -0.37593265, -0.46241663,\n",
       "        0.53907536,  0.15501931, -0.20648296,  0.04277133, -0.37305712])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(estimator=xgboost_best, X=x_test, y=y_test, cv=folds, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.36968716,  0.50656648,  0.37753683, -0.35287715, -0.89388905,\n",
       "        0.61267725,  0.27556721, -0.52265983, -0.09172963, -0.50688134])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(estimator=xgboost, X=x_test, y=y_test, cv=folds, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
