{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Scikit Learn libraries\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Scipy libraries\n",
    "from scipy import stats\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Utils functions\n",
    "from utils.utils import kfold, five_two, read_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = read_datasets(\n",
    "    'x_train.csv',\n",
    "    'x_test.csv',\n",
    "    'y_train.csv',\n",
    "    'y_test.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting regression - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cross validation scheme to be used for train and test\n",
    "folds = kfold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n",
      "{'tree_method': 'auto', 'subsample': 0.5, 'reg_lambda': 1, 'objective': 'reg:squarederror', 'n_estimators': 50, 'min_child_weight': 3, 'max_leaves': 1, 'max_depth': 6, 'max_delta_step': 5, 'grow_policy': 'depthwise', 'gamma': 1, 'eval_metric': 'mae', 'eta': 0.4, 'colsample_bytree': 0.2, 'booster': 'gbtree', 'base_score': 0.4, 'alpha': 0}\n"
     ]
    }
   ],
   "source": [
    "# Specify range of hyperparameters to tune\n",
    "hyper_params = {\n",
    "    'colsample_bytree': [0.2, 0.3, 0.4],\n",
    "    #'learning_rate': [0.15, 2],\n",
    "    'n_estimators': [25, 50],\n",
    "    'subsample': [0.5, 0.8, 1],\n",
    "    'max_depth': [1, 2, 3, 6],\n",
    "    'booster': ['gbtree'],\n",
    "    'objective': [\"reg:squarederror\"],\n",
    "    'eta': [0.3, 0.4, 0.5, 0.6],\n",
    "    'gamma': [0, 1],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'max_delta_step':[0, 1, 5],\n",
    "    'reg_lambda': [1],\n",
    "    'alpha': [0],\n",
    "    'tree_method': ['auto', 'exact'],\n",
    "    'max_leaves': [0, 1, 5],\n",
    "    'eval_metric': ['mae', 'rmse'],\n",
    "    'base_score': [0.4, 0.5, 0.7],\n",
    "    'grow_policy': ['depthwise']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Call GridSearchCV()\n",
    "model_cv = RandomizedSearchCV(\n",
    "    estimator = xgb.XGBRegressor(),\n",
    "    param_distributions = hyper_params,\n",
    "    n_iter=200,\n",
    "    scoring= 'r2',\n",
    "    cv = folds,\n",
    "    verbose = 2,\n",
    "    return_train_score=True,\n",
    "    n_jobs = -1,\n",
    "    refit = True\n",
    "    )\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "best_model = model_cv.fit(x_train, np.ravel(y_train)) \n",
    "\n",
    "print(model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=0, base_score=0.4, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.2,\n",
       "             early_stopping_rounds=None, enable_categorical=False, eta=0.4,\n",
       "             eval_metric='mae', gamma=1, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.400000006, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=5, max_depth=6, max_leaves=1, min_child_weight=3,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=50, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new model with best_params_ from grid search\n",
    "# Use cross validation on the best_params_ model\n",
    "\n",
    "xgboost_best = xgb.XGBRegressor(\n",
    "    colsample_bytree=model_cv.best_params_['colsample_bytree'],\n",
    "    n_estimators=model_cv.best_params_['n_estimators'],\n",
    "    subsample=model_cv.best_params_['subsample'],\n",
    "    max_depth=model_cv.best_params_['max_depth'],\n",
    "    #learning_rate=model_cv.best_params_['learning_rate'],\n",
    "    booster=model_cv.best_params_['booster'],\n",
    "    objective=model_cv.best_params_['objective'],\n",
    "    eta=model_cv.best_params_['eta'],\n",
    "    gamma=model_cv.best_params_['gamma'],\n",
    "    min_child_weight=model_cv.best_params_['min_child_weight'],\n",
    "    max_delta_step=model_cv.best_params_['max_delta_step'],\n",
    "    reg_lambda=model_cv.best_params_['reg_lambda'],\n",
    "    alpha=model_cv.best_params_['alpha'],\n",
    "    tree_method=model_cv.best_params_['tree_method'],\n",
    "    max_leaves=model_cv.best_params_['max_leaves'],\n",
    "    eval_metric=model_cv.best_params_['eval_metric'],\n",
    "    base_score=model_cv.best_params_['base_score'],\n",
    "    grow_policy=model_cv.best_params_['grow_policy']\n",
    "    )\n",
    "\n",
    "\n",
    "xgboost_best.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 score on test set: 0.2899\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(y_test, xgboost_best.predict(x_test))\n",
    "print(\"The r2 score on test set: {:.4f}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/xgboost_model.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../models/xgboost_model.joblib'\n",
    "joblib.dump(xgboost_best, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
